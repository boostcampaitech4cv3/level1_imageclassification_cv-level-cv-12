{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf046c11-3a01-4c6c-99dd-c062e21c7bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bad9118-3244-4b50-bce3-d9f0ca8dc7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  0% |\n",
      "|  1 |  0% |  0% |\n"
     ]
    }
   ],
   "source": [
    "import GPUtil\n",
    "GPUtil.showUtilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b1d65a3-78de-4b01-a862-e6bd4c7ef135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from align_faces import warp_and_crop_face, get_reference_facial_points\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "#from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import os\n",
    "from torchmetrics import F1Score\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa8d19de-5a8e-454f-a22b-129e94792395",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 12\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f69f93c-5675-433f-8a88-7bf8e411d51c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>path</th>\n",
       "      <th>age_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>45</td>\n",
       "      <td>000001_female_Asian_45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000002</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>52</td>\n",
       "      <td>000002_female_Asian_52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000004</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>54</td>\n",
       "      <td>000004_male_Asian_54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000005</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>58</td>\n",
       "      <td>000005_female_Asian_58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000006</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>59</td>\n",
       "      <td>000006_female_Asian_59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2695</th>\n",
       "      <td>006954</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19</td>\n",
       "      <td>006954_male_Asian_19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2696</th>\n",
       "      <td>006955</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19</td>\n",
       "      <td>006955_male_Asian_19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2697</th>\n",
       "      <td>006956</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19</td>\n",
       "      <td>006956_male_Asian_19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2698</th>\n",
       "      <td>006957</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>20</td>\n",
       "      <td>006957_male_Asian_20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2699</th>\n",
       "      <td>006959</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19</td>\n",
       "      <td>006959_male_Asian_19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2700 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  gender   race  age                    path  age_range\n",
       "0     000001  female  Asian   45  000001_female_Asian_45          1\n",
       "1     000002  female  Asian   52  000002_female_Asian_52          1\n",
       "2     000004    male  Asian   54    000004_male_Asian_54          1\n",
       "3     000005  female  Asian   58  000005_female_Asian_58          1\n",
       "4     000006  female  Asian   59  000006_female_Asian_59          1\n",
       "...      ...     ...    ...  ...                     ...        ...\n",
       "2695  006954    male  Asian   19    006954_male_Asian_19          0\n",
       "2696  006955    male  Asian   19    006955_male_Asian_19          0\n",
       "2697  006956    male  Asian   19    006956_male_Asian_19          0\n",
       "2698  006957    male  Asian   20    006957_male_Asian_20          0\n",
       "2699  006959    male  Asian   19    006959_male_Asian_19          0\n",
       "\n",
       "[2700 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir_path = '../input/data/train/'\n",
    "train_image_path = '../input/data/train/images/'\n",
    "\n",
    "dt_train = pd.read_csv(train_dir_path+'train.csv')\n",
    "exp_train = pd.read_csv(train_dir_path+'expanded_train.csv')\n",
    "\n",
    "def get_age_range(age):\n",
    "    if age < 30:\n",
    "        return 0\n",
    "    elif 30 <= age < 60:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "dt_train['age_range'] = dt_train['age'].apply(lambda x : get_age_range(x))\n",
    "dt_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c92579a9-3de4-463c-9041-53d5b1e403b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>path</th>\n",
       "      <th>age_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>000077</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>59</td>\n",
       "      <td>000077_male_Asian_59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2141</th>\n",
       "      <td>005420</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>48</td>\n",
       "      <td>005420_female_Asian_48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2029</th>\n",
       "      <td>005106</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>54</td>\n",
       "      <td>005106_female_Asian_54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>001217</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>25</td>\n",
       "      <td>001217_female_Asian_25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2188</th>\n",
       "      <td>005478</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>43</td>\n",
       "      <td>005478_female_Asian_43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>001723</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>35</td>\n",
       "      <td>001723_female_Asian_35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570</th>\n",
       "      <td>003724</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>58</td>\n",
       "      <td>003724_female_Asian_58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1624</th>\n",
       "      <td>003791</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>50</td>\n",
       "      <td>003791_female_Asian_50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643</th>\n",
       "      <td>003813</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>51</td>\n",
       "      <td>003813_male_Asian_51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>000639</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>54</td>\n",
       "      <td>000639_female_Asian_54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  gender   race  age                    path  age_range\n",
       "49    000077    male  Asian   59    000077_male_Asian_59          1\n",
       "2141  005420  female  Asian   48  005420_female_Asian_48          1\n",
       "2029  005106  female  Asian   54  005106_female_Asian_54          1\n",
       "574   001217  female  Asian   25  001217_female_Asian_25          0\n",
       "2188  005478  female  Asian   43  005478_female_Asian_43          1\n",
       "...      ...     ...    ...  ...                     ...        ...\n",
       "936   001723  female  Asian   35  001723_female_Asian_35          1\n",
       "1570  003724  female  Asian   58  003724_female_Asian_58          1\n",
       "1624  003791  female  Asian   50  003791_female_Asian_50          1\n",
       "1643  003813    male  Asian   51    003813_male_Asian_51          1\n",
       "237   000639  female  Asian   54  000639_female_Asian_54          1\n",
       "\n",
       "[70 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx, valid_idx = train_test_split(np.arange(len(dt_train)),\n",
    "                                       test_size=0.2,\n",
    "                                       shuffle=True,\n",
    "                                       stratify=dt_train['age_range'])\n",
    "dt_train.iloc[train_idx].head(70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7cdaaac-b38a-471a-90b9-012521adb5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index size: 2160 == file estimate: 15120 == split size: 15127\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PersonID</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Class</th>\n",
       "      <th>Mask</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Age_Class</th>\n",
       "      <th>Has_Face</th>\n",
       "      <th>BBoxX1</th>\n",
       "      <th>...</th>\n",
       "      <th>LE_X</th>\n",
       "      <th>LE_Y</th>\n",
       "      <th>RE_X</th>\n",
       "      <th>RE_Y</th>\n",
       "      <th>N_X</th>\n",
       "      <th>N_Y</th>\n",
       "      <th>LM_X</th>\n",
       "      <th>LM_Y</th>\n",
       "      <th>RM_X</th>\n",
       "      <th>RM_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>000001</td>\n",
       "      <td>../input/data/train/images/000001_female_Asian...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>122</td>\n",
       "      <td>...</td>\n",
       "      <td>152</td>\n",
       "      <td>205</td>\n",
       "      <td>211</td>\n",
       "      <td>202</td>\n",
       "      <td>182</td>\n",
       "      <td>245</td>\n",
       "      <td>164</td>\n",
       "      <td>275</td>\n",
       "      <td>205</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>000001</td>\n",
       "      <td>../input/data/train/images/000001_female_Asian...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>110</td>\n",
       "      <td>...</td>\n",
       "      <td>139</td>\n",
       "      <td>232</td>\n",
       "      <td>209</td>\n",
       "      <td>234</td>\n",
       "      <td>171</td>\n",
       "      <td>275</td>\n",
       "      <td>151</td>\n",
       "      <td>307</td>\n",
       "      <td>194</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>000001</td>\n",
       "      <td>../input/data/train/images/000001_female_Asian...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>112</td>\n",
       "      <td>...</td>\n",
       "      <td>145</td>\n",
       "      <td>230</td>\n",
       "      <td>206</td>\n",
       "      <td>230</td>\n",
       "      <td>176</td>\n",
       "      <td>268</td>\n",
       "      <td>158</td>\n",
       "      <td>296</td>\n",
       "      <td>198</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>000001</td>\n",
       "      <td>../input/data/train/images/000001_female_Asian...</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>126</td>\n",
       "      <td>...</td>\n",
       "      <td>154</td>\n",
       "      <td>223</td>\n",
       "      <td>213</td>\n",
       "      <td>219</td>\n",
       "      <td>184</td>\n",
       "      <td>260</td>\n",
       "      <td>164</td>\n",
       "      <td>288</td>\n",
       "      <td>213</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>000001</td>\n",
       "      <td>../input/data/train/images/000001_female_Asian...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>150</td>\n",
       "      <td>223</td>\n",
       "      <td>210</td>\n",
       "      <td>219</td>\n",
       "      <td>182</td>\n",
       "      <td>257</td>\n",
       "      <td>165</td>\n",
       "      <td>289</td>\n",
       "      <td>204</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18888</th>\n",
       "      <td>18888</td>\n",
       "      <td>006957</td>\n",
       "      <td>../input/data/train/images/006957_male_Asian_2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>110</td>\n",
       "      <td>...</td>\n",
       "      <td>150</td>\n",
       "      <td>226</td>\n",
       "      <td>223</td>\n",
       "      <td>222</td>\n",
       "      <td>190</td>\n",
       "      <td>270</td>\n",
       "      <td>164</td>\n",
       "      <td>306</td>\n",
       "      <td>217</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18889</th>\n",
       "      <td>18889</td>\n",
       "      <td>006957</td>\n",
       "      <td>../input/data/train/images/006957_male_Asian_2...</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>103</td>\n",
       "      <td>...</td>\n",
       "      <td>142</td>\n",
       "      <td>227</td>\n",
       "      <td>212</td>\n",
       "      <td>223</td>\n",
       "      <td>178</td>\n",
       "      <td>267</td>\n",
       "      <td>154</td>\n",
       "      <td>310</td>\n",
       "      <td>210</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18890</th>\n",
       "      <td>18890</td>\n",
       "      <td>006957</td>\n",
       "      <td>../input/data/train/images/006957_male_Asian_2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>94</td>\n",
       "      <td>...</td>\n",
       "      <td>137</td>\n",
       "      <td>225</td>\n",
       "      <td>209</td>\n",
       "      <td>225</td>\n",
       "      <td>178</td>\n",
       "      <td>267</td>\n",
       "      <td>151</td>\n",
       "      <td>303</td>\n",
       "      <td>202</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18891</th>\n",
       "      <td>18891</td>\n",
       "      <td>006957</td>\n",
       "      <td>../input/data/train/images/006957_male_Asian_2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>103</td>\n",
       "      <td>...</td>\n",
       "      <td>144</td>\n",
       "      <td>220</td>\n",
       "      <td>219</td>\n",
       "      <td>217</td>\n",
       "      <td>185</td>\n",
       "      <td>269</td>\n",
       "      <td>159</td>\n",
       "      <td>304</td>\n",
       "      <td>212</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18892</th>\n",
       "      <td>18892</td>\n",
       "      <td>006957</td>\n",
       "      <td>../input/data/train/images/006957_male_Asian_2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>111</td>\n",
       "      <td>...</td>\n",
       "      <td>152</td>\n",
       "      <td>235</td>\n",
       "      <td>237</td>\n",
       "      <td>233</td>\n",
       "      <td>195</td>\n",
       "      <td>296</td>\n",
       "      <td>168</td>\n",
       "      <td>332</td>\n",
       "      <td>230</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15127 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0 PersonID                                           Filename  \\\n",
       "0               0   000001  ../input/data/train/images/000001_female_Asian...   \n",
       "1               1   000001  ../input/data/train/images/000001_female_Asian...   \n",
       "2               2   000001  ../input/data/train/images/000001_female_Asian...   \n",
       "3               3   000001  ../input/data/train/images/000001_female_Asian...   \n",
       "4               4   000001  ../input/data/train/images/000001_female_Asian...   \n",
       "...           ...      ...                                                ...   \n",
       "18888       18888   006957  ../input/data/train/images/006957_male_Asian_2...   \n",
       "18889       18889   006957  ../input/data/train/images/006957_male_Asian_2...   \n",
       "18890       18890   006957  ../input/data/train/images/006957_male_Asian_2...   \n",
       "18891       18891   006957  ../input/data/train/images/006957_male_Asian_2...   \n",
       "18892       18892   006957  ../input/data/train/images/006957_male_Asian_2...   \n",
       "\n",
       "       Class  Mask  Gender  Age  Age_Class  Has_Face  BBoxX1  ...  LE_X  LE_Y  \\\n",
       "0         10     1       1   45          1      True     122  ...   152   205   \n",
       "1          4     0       1   45          1      True     110  ...   139   232   \n",
       "2          4     0       1   45          1      True     112  ...   145   230   \n",
       "3         16     2       1   45          1      True     126  ...   154   223   \n",
       "4          4     0       1   45          1      True     120  ...   150   223   \n",
       "...      ...   ...     ...  ...        ...       ...     ...  ...   ...   ...   \n",
       "18888      0     0       0   20          0      True     110  ...   150   226   \n",
       "18889     12     2       0   20          0      True     103  ...   142   227   \n",
       "18890      0     0       0   20          0      True      94  ...   137   225   \n",
       "18891      0     0       0   20          0      True     103  ...   144   220   \n",
       "18892      0     0       0   20          0      True     111  ...   152   235   \n",
       "\n",
       "       RE_X  RE_Y  N_X  N_Y  LM_X  LM_Y  RM_X  RM_Y  \n",
       "0       211   202  182  245   164   275   205   273  \n",
       "1       209   234  171  275   151   307   194   309  \n",
       "2       206   230  176  268   158   296   198   297  \n",
       "3       213   219  184  260   164   288   213   284  \n",
       "4       210   219  182  257   165   289   204   287  \n",
       "...     ...   ...  ...  ...   ...   ...   ...   ...  \n",
       "18888   223   222  190  270   164   306   217   302  \n",
       "18889   212   223  178  267   154   310   210   307  \n",
       "18890   209   225  178  267   151   303   202   303  \n",
       "18891   219   217  185  269   159   304   212   302  \n",
       "18892   237   233  195  296   168   332   230   330  \n",
       "\n",
       "[15127 rows x 24 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_exp_train = exp_train[exp_train['PersonID'].isin(list(dt_train.iloc[train_idx][\"id\"]))]\n",
    "split_exp_valid = exp_train[exp_train['PersonID'].isin(list(dt_train.iloc[valid_idx][\"id\"]))]\n",
    "print(f\"index size: {len(train_idx)} == file estimate: {len(train_idx) * 7} == split size: {len(split_exp_train)}\")\n",
    "split_exp_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "304c6a61-ff17-4777-8132-18def61c8102",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image = split_exp_train.loc[:,\"Filename\"]\n",
    "train_label = split_exp_train.loc[:,\"Class\"]\n",
    "\n",
    "valid_image = split_exp_valid.loc[:,\"Filename\"]\n",
    "valid_label = split_exp_valid.loc[:,\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "694474c7-7175-40e6-b071-e50218629f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.Series(train_image)\n",
    "train_label = pd.Series(train_label)\n",
    "\n",
    "valid_data = pd.Series(valid_image)\n",
    "valid_label = pd.Series(valid_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2cd7b29-5f03-444e-b781-902ca74f2085",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Resize, ToTensor, Normalize, Compose, CenterCrop, ColorJitter\n",
    "from PIL import Image\n",
    "\n",
    "default_square = True\n",
    "inner_padding_factor = 0.05\n",
    "outer_padding = (0, 0)\n",
    "#output_size = (224, 224)\n",
    "output_size = (384, 384)\n",
    "\n",
    "class Dataset_Mask(Dataset):\n",
    "    def __init__(self, data, label, encoding=True, midcrop=True, transform=None, is_train=True):\n",
    "        self.encoding = encoding\n",
    "        self.midcrop = midcrop\n",
    "        self.data = data.reset_index(drop=True)\n",
    "        self.is_train = is_train\n",
    "        self.label = label.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "        \"\"\"\n",
    "        self.images = list()\n",
    "        for idx in range(len(self.data)):\n",
    "            img_raw = np.load(self.data[idx])\n",
    "        \n",
    "            # X = X[64:448]\n",
    "            source_df = split_exp_train if self.is_train else split_exp_valid\n",
    "            facial5points = [[source_df.iloc[idx]['LE_X'], source_df.iloc[idx]['LE_Y']],\n",
    "                             [source_df.iloc[idx]['RE_X'], source_df.iloc[idx]['RE_Y']],\n",
    "                             [source_df.iloc[idx][ 'N_X'], source_df.iloc[idx][ 'N_Y']],\n",
    "                             [source_df.iloc[idx]['LM_X'], source_df.iloc[idx]['LM_Y']],\n",
    "                             [source_df.iloc[idx]['RM_X'], source_df.iloc[idx]['RM_Y']]]\n",
    "            reference_5pts = get_reference_facial_points(output_size, inner_padding_factor, outer_padding, default_square)\n",
    "            align_crop_img = warp_and_crop_face(img_raw, facial5points, reference_pts=reference_5pts, crop_size=output_size)\n",
    "\n",
    "            self.images.append(align_crop_img)\n",
    "        \"\"\"\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_raw = np.load(self.data[idx])\n",
    "\n",
    "        # X = X[64:448]\n",
    "        source_df = split_exp_train if self.is_train else split_exp_valid\n",
    "        facial5points = [[source_df.iloc[idx]['LE_X'], source_df.iloc[idx]['LE_Y']],\n",
    "                         [source_df.iloc[idx]['RE_X'], source_df.iloc[idx]['RE_Y']],\n",
    "                         [source_df.iloc[idx][ 'N_X'], source_df.iloc[idx][ 'N_Y']],\n",
    "                         [source_df.iloc[idx]['LM_X'], source_df.iloc[idx]['LM_Y']],\n",
    "                         [source_df.iloc[idx]['RM_X'], source_df.iloc[idx]['RM_Y']]]\n",
    "        reference_5pts = get_reference_facial_points(output_size, inner_padding_factor, outer_padding, default_square)\n",
    "        X = warp_and_crop_face(img_raw, facial5points, reference_pts=reference_5pts, crop_size=output_size)\n",
    "        y = self.label[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            return self.transform(X), y\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2a22aff-e634-4f15-877c-752d450d01da",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_train_set = Dataset_Mask(data=train_data, label=train_label, is_train=True, transform=transforms.Compose([\n",
    "                                    ToTensor(),\n",
    "                                    #Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "                            ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "caf9fd0a-27a3-4ba1-ab39-fea87ac96227",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_val_set = Dataset_Mask(data=valid_data, label=valid_label, is_train=False, transform = transforms.Compose([\n",
    "                                    ToTensor(),\n",
    "                                    #Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "                            ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5788c44b-07ac-4820-a22d-b6ffa3fc81f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#t_image = [mask_train_set[i][1] for i in tqdm(range(len(mask_train_set)))]\n",
    "#v_image = [mask_val_set[i][1] for i in tqdm(range(len(mask_val_set)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7141916-f044-49fc-a1aa-2e977c0919b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#t_df = pd.DataFrame(t_image, columns=['counts'])\n",
    "#v_df = pd.DataFrame(v_image, columns=['counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "007c8fde-fa5d-4712-961c-c5c97a04bff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import seaborn as sns\n",
    "\n",
    "#fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "#sns.countplot(x='counts', data=t_df, ax=axes[0])\n",
    "#axes[0].set_xlabel(\"train set labels\")\n",
    "#sns.countplot(x='counts', data=v_df, ax=axes[1])\n",
    "#axes[1].set_xlabel(\"valid set labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e285cb6-ee37-4a0c-a804-7506dcfebc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f'training data size : {len(mask_train_set)}')\n",
    "#print(f'validation data size : {len(mask_val_set)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37b1ced0-1e34-4d50-b2b2-dcdff8fd33f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "train_dataloader_mask = DataLoader(dataset = mask_train_set, batch_size=batch_size, num_workers=2)\n",
    "val_dataloader_mask = DataLoader(dataset = mask_val_set, batch_size=batch_size, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af71a4ef-a137-47b0-af94-eebedaa36014",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "필요 입력 채널 개수 3\n",
      "네트워크 출력 채널 개수 1000\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "basemodel_resnet34 = torchvision.models.resnet34(pretrained=True)\n",
    "print('필요 입력 채널 개수', basemodel_resnet34.conv1.weight.shape[1])\n",
    "print('네트워크 출력 채널 개수', basemodel_resnet34.fc.weight.shape[0])\n",
    "print(basemodel_resnet34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11357fc4-548b-452e-bbd8-e60ef6261308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "필요 입력 채널 개수 3\n",
      "네트워크 출력 채널 개수 18\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "class_num = 18\n",
    "basemodel_resnet34.fc = nn.Linear(in_features=512, out_features=class_num, bias=True)\n",
    "nn.init.xavier_uniform_(basemodel_resnet34.fc.weight)\n",
    "stdv = 1. / math.sqrt(basemodel_resnet34.fc.weight.size(1))\n",
    "basemodel_resnet34.fc.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "print('필요 입력 채널 개수', basemodel_resnet34.conv1.weight.shape[1])\n",
    "print('네트워크 출력 채널 개수', basemodel_resnet34.fc.weight.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a1a2262-f820-4294-8086-3a48a5e5d686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"using {device}\")\n",
    "\n",
    "basemodel_resnet34 = torch.nn.DataParallel(basemodel_resnet34)\n",
    "basemodel_resnet34.to(device)\n",
    "\n",
    "LEARNING_RATE = 0.0001\n",
    "NUM_EPOCH = 50\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(basemodel_resnet34.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "#lr = 1e-3\n",
    "#betas = (0.9, 0.999)\n",
    "#weight_decay = 0.5e-4\n",
    "#eps = 1e-8\n",
    "#optimizer = torch.optim.AdamW(basemodel_resnet34.parameters(), lr=lr, betas=betas, weight_decay=weight_decay, eps=eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64a36f92-aad5-4bbb-a920-29d50f0f058b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] name:[module.conv1.weight] shape:[(64, 3, 7, 7)].\n",
      "    val:[ 0.005 -0.007  0.008  0.038  0.049]\n",
      "    --[True].\n",
      "[1] name:[module.bn1.weight] shape:[(64,)].\n",
      "    val:[0.302 0.268 0.26  0.311 0.238]\n",
      "    --[True].\n",
      "[2] name:[module.bn1.bias] shape:[(64,)].\n",
      "    val:[0.481 0.207 0.331 0.38  0.094]\n",
      "    --[True].\n",
      "[3] name:[module.layer1.0.conv1.weight] shape:[(64, 64, 3, 3)].\n",
      "    val:[-0.005  0.015 -0.006 -0.06  -0.024]\n",
      "    --[True].\n",
      "[4] name:[module.layer1.0.bn1.weight] shape:[(64,)].\n",
      "    val:[0.24  0.185 0.216 0.165 0.181]\n",
      "    --[True].\n",
      "[5] name:[module.layer1.0.bn1.bias] shape:[(64,)].\n",
      "    val:[0.025 0.088 0.082 0.142 0.066]\n",
      "    --[True].\n",
      "[6] name:[module.layer1.0.conv2.weight] shape:[(64, 64, 3, 3)].\n",
      "    val:[ 0.066 -0.01   0.041  0.033 -0.055]\n",
      "    --[True].\n",
      "[7] name:[module.layer1.0.bn2.weight] shape:[(64,)].\n",
      "    val:[0.34  0.187 0.252 0.307 0.259]\n",
      "    --[True].\n",
      "[8] name:[module.layer1.0.bn2.bias] shape:[(64,)].\n",
      "    val:[-0.251  0.196  0.23  -0.114  0.07 ]\n",
      "    --[True].\n",
      "[9] name:[module.layer1.1.conv1.weight] shape:[(64, 64, 3, 3)].\n",
      "    val:[-0.008 -0.04  -0.054 -0.019  0.011]\n",
      "    --[True].\n",
      "[10] name:[module.layer1.1.bn1.weight] shape:[(64,)].\n",
      "    val:[0.178 0.373 0.18  0.26  0.246]\n",
      "    --[True].\n",
      "[11] name:[module.layer1.1.bn1.bias] shape:[(64,)].\n",
      "    val:[ 0.073 -0.222  0.177 -0.063 -0.051]\n",
      "    --[True].\n",
      "[12] name:[module.layer1.1.conv2.weight] shape:[(64, 64, 3, 3)].\n",
      "    val:[-0.002 -0.04  -0.012  0.008  0.088]\n",
      "    --[True].\n",
      "[13] name:[module.layer1.1.bn2.weight] shape:[(64,)].\n",
      "    val:[0.417 0.209 0.224 0.179 0.402]\n",
      "    --[True].\n",
      "[14] name:[module.layer1.1.bn2.bias] shape:[(64,)].\n",
      "    val:[-0.033 -0.08   0.174 -0.102  0.176]\n",
      "    --[True].\n",
      "[15] name:[module.layer1.2.conv1.weight] shape:[(64, 64, 3, 3)].\n",
      "    val:[ 0.021 -0.101 -0.024  0.013  0.111]\n",
      "    --[True].\n",
      "[16] name:[module.layer1.2.bn1.weight] shape:[(64,)].\n",
      "    val:[0.335 0.203 0.192 0.247 0.248]\n",
      "    --[True].\n",
      "[17] name:[module.layer1.2.bn1.bias] shape:[(64,)].\n",
      "    val:[-0.266 -0.041 -0.11  -0.246  0.017]\n",
      "    --[True].\n",
      "[18] name:[module.layer1.2.conv2.weight] shape:[(64, 64, 3, 3)].\n",
      "    val:[-0.017  0.023 -0.021 -0.04   0.042]\n",
      "    --[True].\n",
      "[19] name:[module.layer1.2.bn2.weight] shape:[(64,)].\n",
      "    val:[0.554 0.169 0.286 0.193 0.248]\n",
      "    --[True].\n",
      "[20] name:[module.layer1.2.bn2.bias] shape:[(64,)].\n",
      "    val:[-0.093 -0.217  0.121  0.058  0.072]\n",
      "    --[True].\n",
      "[21] name:[module.layer2.0.conv1.weight] shape:[(128, 64, 3, 3)].\n",
      "    val:[-0.007  0.001 -0.007 -0.024  0.034]\n",
      "    --[True].\n",
      "[22] name:[module.layer2.0.bn1.weight] shape:[(128,)].\n",
      "    val:[0.261 0.288 0.174 0.238 0.274]\n",
      "    --[True].\n",
      "[23] name:[module.layer2.0.bn1.bias] shape:[(128,)].\n",
      "    val:[-0.083 -0.094  0.286 -0.043 -0.101]\n",
      "    --[True].\n",
      "[24] name:[module.layer2.0.conv2.weight] shape:[(128, 128, 3, 3)].\n",
      "    val:[-0.005 -0.025  0.025  0.007 -0.021]\n",
      "    --[True].\n",
      "[25] name:[module.layer2.0.bn2.weight] shape:[(128,)].\n",
      "    val:[0.376 0.01  0.186 0.269 0.344]\n",
      "    --[True].\n",
      "[26] name:[module.layer2.0.bn2.bias] shape:[(128,)].\n",
      "    val:[-0.068  0.218  0.066  0.078  0.135]\n",
      "    --[True].\n",
      "[27] name:[module.layer2.0.downsample.0.weight] shape:[(128, 64, 1, 1)].\n",
      "    val:[-0.008 -0.109  0.045 -0.033 -0.003]\n",
      "    --[True].\n",
      "[28] name:[module.layer2.0.downsample.1.weight] shape:[(128,)].\n",
      "    val:[0.169 0.36  0.406 0.076 0.207]\n",
      "    --[True].\n",
      "[29] name:[module.layer2.0.downsample.1.bias] shape:[(128,)].\n",
      "    val:[-0.068  0.218  0.066  0.078  0.135]\n",
      "    --[True].\n",
      "[30] name:[module.layer2.1.conv1.weight] shape:[(128, 128, 3, 3)].\n",
      "    val:[-0.011 -0.004  0.012 -0.015 -0.011]\n",
      "    --[True].\n",
      "[31] name:[module.layer2.1.bn1.weight] shape:[(128,)].\n",
      "    val:[0.157 0.302 0.154 0.311 0.211]\n",
      "    --[True].\n",
      "[32] name:[module.layer2.1.bn1.bias] shape:[(128,)].\n",
      "    val:[ 0.063 -0.199  0.054 -0.259 -0.036]\n",
      "    --[True].\n",
      "[33] name:[module.layer2.1.conv2.weight] shape:[(128, 128, 3, 3)].\n",
      "    val:[ 0.022 -0.006  0.029  0.001 -0.023]\n",
      "    --[True].\n",
      "[34] name:[module.layer2.1.bn2.weight] shape:[(128,)].\n",
      "    val:[0.146 0.271 0.169 0.162 0.091]\n",
      "    --[True].\n",
      "[35] name:[module.layer2.1.bn2.bias] shape:[(128,)].\n",
      "    val:[-0.064 -0.481 -0.127 -0.03  -0.03 ]\n",
      "    --[True].\n",
      "[36] name:[module.layer2.2.conv1.weight] shape:[(128, 128, 3, 3)].\n",
      "    val:[ 0.039  0.004 -0.007  0.008  0.01 ]\n",
      "    --[True].\n",
      "[37] name:[module.layer2.2.bn1.weight] shape:[(128,)].\n",
      "    val:[0.28  0.303 0.248 0.216 0.235]\n",
      "    --[True].\n",
      "[38] name:[module.layer2.2.bn1.bias] shape:[(128,)].\n",
      "    val:[-0.211 -0.532 -0.127 -0.146 -0.088]\n",
      "    --[True].\n",
      "[39] name:[module.layer2.2.conv2.weight] shape:[(128, 128, 3, 3)].\n",
      "    val:[-0.04  -0.046 -0.016 -0.017  0.006]\n",
      "    --[True].\n",
      "[40] name:[module.layer2.2.bn2.weight] shape:[(128,)].\n",
      "    val:[0.25  0.102 0.138 0.317 0.144]\n",
      "    --[True].\n",
      "[41] name:[module.layer2.2.bn2.bias] shape:[(128,)].\n",
      "    val:[-0.051  0.006  0.007 -0.147  0.035]\n",
      "    --[True].\n",
      "[42] name:[module.layer2.3.conv1.weight] shape:[(128, 128, 3, 3)].\n",
      "    val:[-0.016 -0.033  0.011 -0.001 -0.038]\n",
      "    --[True].\n",
      "[43] name:[module.layer2.3.bn1.weight] shape:[(128,)].\n",
      "    val:[0.216 0.181 0.23  0.205 0.245]\n",
      "    --[True].\n",
      "[44] name:[module.layer2.3.bn1.bias] shape:[(128,)].\n",
      "    val:[-0.179 -0.142 -0.17  -0.189 -0.196]\n",
      "    --[True].\n",
      "[45] name:[module.layer2.3.conv2.weight] shape:[(128, 128, 3, 3)].\n",
      "    val:[ 0.012 -0.026 -0.027 -0.002 -0.029]\n",
      "    --[True].\n",
      "[46] name:[module.layer2.3.bn2.weight] shape:[(128,)].\n",
      "    val:[ 0.194 -0.018  0.164  0.281  0.151]\n",
      "    --[True].\n",
      "[47] name:[module.layer2.3.bn2.bias] shape:[(128,)].\n",
      "    val:[ 0.117  0.032 -0.26  -0.127 -0.086]\n",
      "    --[True].\n",
      "[48] name:[module.layer3.0.conv1.weight] shape:[(256, 128, 3, 3)].\n",
      "    val:[ 0.007 -0.013  0.008 -0.018 -0.007]\n",
      "    --[True].\n",
      "[49] name:[module.layer3.0.bn1.weight] shape:[(256,)].\n",
      "    val:[0.274 0.267 0.268 0.232 0.234]\n",
      "    --[True].\n",
      "[50] name:[module.layer3.0.bn1.bias] shape:[(256,)].\n",
      "    val:[-0.06  -0.081 -0.092  0.066  0.037]\n",
      "    --[True].\n",
      "[51] name:[module.layer3.0.conv2.weight] shape:[(256, 256, 3, 3)].\n",
      "    val:[ 0.007  0.005 -0.012 -0.008 -0.003]\n",
      "    --[True].\n",
      "[52] name:[module.layer3.0.bn2.weight] shape:[(256,)].\n",
      "    val:[0.349 0.329 0.257 0.217 0.355]\n",
      "    --[True].\n",
      "[53] name:[module.layer3.0.bn2.bias] shape:[(256,)].\n",
      "    val:[-0.097 -0.09   0.072  0.154 -0.044]\n",
      "    --[True].\n",
      "[54] name:[module.layer3.0.downsample.0.weight] shape:[(256, 128, 1, 1)].\n",
      "    val:[-0.022  0.023  0.002 -0.014 -0.019]\n",
      "    --[True].\n",
      "[55] name:[module.layer3.0.downsample.1.weight] shape:[(256,)].\n",
      "    val:[0.143 0.159 0.071 0.082 0.114]\n",
      "    --[True].\n",
      "[56] name:[module.layer3.0.downsample.1.bias] shape:[(256,)].\n",
      "    val:[-0.097 -0.09   0.072  0.154 -0.044]\n",
      "    --[True].\n",
      "[57] name:[module.layer3.1.conv1.weight] shape:[(256, 256, 3, 3)].\n",
      "    val:[-0.001 -0.01  -0.013  0.001 -0.002]\n",
      "    --[True].\n",
      "[58] name:[module.layer3.1.bn1.weight] shape:[(256,)].\n",
      "    val:[0.22  0.208 0.202 0.218 0.215]\n",
      "    --[True].\n",
      "[59] name:[module.layer3.1.bn1.bias] shape:[(256,)].\n",
      "    val:[-0.185 -0.167 -0.168 -0.18  -0.068]\n",
      "    --[True].\n",
      "[60] name:[module.layer3.1.conv2.weight] shape:[(256, 256, 3, 3)].\n",
      "    val:[ 0.004  0.004  0.016 -0.006 -0.01 ]\n",
      "    --[True].\n",
      "[61] name:[module.layer3.1.bn2.weight] shape:[(256,)].\n",
      "    val:[0.25  0.2   0.122 0.093 0.191]\n",
      "    --[True].\n",
      "[62] name:[module.layer3.1.bn2.bias] shape:[(256,)].\n",
      "    val:[-0.137 -0.085 -0.053 -0.143 -0.108]\n",
      "    --[True].\n",
      "[63] name:[module.layer3.2.conv1.weight] shape:[(256, 256, 3, 3)].\n",
      "    val:[ 0.039 -0.005  0.003  0.02   0.02 ]\n",
      "    --[True].\n",
      "[64] name:[module.layer3.2.bn1.weight] shape:[(256,)].\n",
      "    val:[0.234 0.232 0.264 0.187 0.217]\n",
      "    --[True].\n",
      "[65] name:[module.layer3.2.bn1.bias] shape:[(256,)].\n",
      "    val:[-0.25  -0.252 -0.323 -0.165 -0.182]\n",
      "    --[True].\n",
      "[66] name:[module.layer3.2.conv2.weight] shape:[(256, 256, 3, 3)].\n",
      "    val:[-0.009 -0.025  0.01   0.021 -0.024]\n",
      "    --[True].\n",
      "[67] name:[module.layer3.2.bn2.weight] shape:[(256,)].\n",
      "    val:[0.304 0.184 0.146 0.06  0.261]\n",
      "    --[True].\n",
      "[68] name:[module.layer3.2.bn2.bias] shape:[(256,)].\n",
      "    val:[-0.163 -0.158 -0.014 -0.    -0.137]\n",
      "    --[True].\n",
      "[69] name:[module.layer3.3.conv1.weight] shape:[(256, 256, 3, 3)].\n",
      "    val:[-0.038 -0.003  0.034 -0.018 -0.012]\n",
      "    --[True].\n",
      "[70] name:[module.layer3.3.bn1.weight] shape:[(256,)].\n",
      "    val:[0.212 0.206 0.159 0.265 0.208]\n",
      "    --[True].\n",
      "[71] name:[module.layer3.3.bn1.bias] shape:[(256,)].\n",
      "    val:[-0.225 -0.162 -0.17  -0.415 -0.243]\n",
      "    --[True].\n",
      "[72] name:[module.layer3.3.conv2.weight] shape:[(256, 256, 3, 3)].\n",
      "    val:[-0.01  -0.014  0.006 -0.005  0.017]\n",
      "    --[True].\n",
      "[73] name:[module.layer3.3.bn2.weight] shape:[(256,)].\n",
      "    val:[0.399 0.206 0.196 0.065 0.27 ]\n",
      "    --[True].\n",
      "[74] name:[module.layer3.3.bn2.bias] shape:[(256,)].\n",
      "    val:[-0.316 -0.16  -0.087  0.015 -0.196]\n",
      "    --[True].\n",
      "[75] name:[module.layer3.4.conv1.weight] shape:[(256, 256, 3, 3)].\n",
      "    val:[-0.002 -0.023 -0.029  0.015 -0.   ]\n",
      "    --[True].\n",
      "[76] name:[module.layer3.4.bn1.weight] shape:[(256,)].\n",
      "    val:[0.196 0.196 0.241 0.226 0.21 ]\n",
      "    --[True].\n",
      "[77] name:[module.layer3.4.bn1.bias] shape:[(256,)].\n",
      "    val:[-0.207 -0.197 -0.268 -0.29  -0.261]\n",
      "    --[True].\n",
      "[78] name:[module.layer3.4.conv2.weight] shape:[(256, 256, 3, 3)].\n",
      "    val:[ 0.005  0.001 -0.005  0.028  0.014]\n",
      "    --[True].\n",
      "[79] name:[module.layer3.4.bn2.weight] shape:[(256,)].\n",
      "    val:[0.322 0.201 0.109 0.01  0.282]\n",
      "    --[True].\n",
      "[80] name:[module.layer3.4.bn2.bias] shape:[(256,)].\n",
      "    val:[-0.196 -0.123 -0.071 -0.001 -0.24 ]\n",
      "    --[True].\n",
      "[81] name:[module.layer3.5.conv1.weight] shape:[(256, 256, 3, 3)].\n",
      "    val:[ 0.016  0.005 -0.004  0.028  0.03 ]\n",
      "    --[True].\n",
      "[82] name:[module.layer3.5.bn1.weight] shape:[(256,)].\n",
      "    val:[0.287 0.194 0.268 0.239 0.229]\n",
      "    --[True].\n",
      "[83] name:[module.layer3.5.bn1.bias] shape:[(256,)].\n",
      "    val:[-0.274 -0.299 -0.355 -0.27  -0.238]\n",
      "    --[True].\n",
      "[84] name:[module.layer3.5.conv2.weight] shape:[(256, 256, 3, 3)].\n",
      "    val:[ 0.002  0.012  0.006 -0.007 -0.005]\n",
      "    --[True].\n",
      "[85] name:[module.layer3.5.bn2.weight] shape:[(256,)].\n",
      "    val:[ 0.358  0.252  0.161 -0.03   0.292]\n",
      "    --[True].\n",
      "[86] name:[module.layer3.5.bn2.bias] shape:[(256,)].\n",
      "    val:[-0.317 -0.187  0.042 -0.006 -0.33 ]\n",
      "    --[True].\n",
      "[87] name:[module.layer4.0.conv1.weight] shape:[(512, 256, 3, 3)].\n",
      "    val:[0.023 0.048 0.058 0.017 0.017]\n",
      "    --[True].\n",
      "[88] name:[module.layer4.0.bn1.weight] shape:[(512,)].\n",
      "    val:[0.275 0.262 0.282 0.279 0.251]\n",
      "    --[True].\n",
      "[89] name:[module.layer4.0.bn1.bias] shape:[(512,)].\n",
      "    val:[-0.271 -0.201 -0.171 -0.224 -0.2  ]\n",
      "    --[True].\n",
      "[90] name:[module.layer4.0.conv2.weight] shape:[(512, 512, 3, 3)].\n",
      "    val:[ 0.001  0.001 -0.002 -0.013 -0.018]\n",
      "    --[True].\n",
      "[91] name:[module.layer4.0.bn2.weight] shape:[(512,)].\n",
      "    val:[0.7   0.664 0.803 0.695 0.743]\n",
      "    --[True].\n",
      "[92] name:[module.layer4.0.bn2.bias] shape:[(512,)].\n",
      "    val:[-0.072 -0.131 -0.151 -0.076 -0.066]\n",
      "    --[True].\n",
      "[93] name:[module.layer4.0.downsample.0.weight] shape:[(512, 256, 1, 1)].\n",
      "    val:[-0.004 -0.033  0.005  0.037 -0.014]\n",
      "    --[True].\n",
      "[94] name:[module.layer4.0.downsample.1.weight] shape:[(512,)].\n",
      "    val:[0.325 0.38  0.501 0.42  0.451]\n",
      "    --[True].\n",
      "[95] name:[module.layer4.0.downsample.1.bias] shape:[(512,)].\n",
      "    val:[-0.072 -0.131 -0.151 -0.076 -0.066]\n",
      "    --[True].\n",
      "[96] name:[module.layer4.1.conv1.weight] shape:[(512, 512, 3, 3)].\n",
      "    val:[ 0.005 -0.005  0.007  0.003  0.003]\n",
      "    --[True].\n",
      "[97] name:[module.layer4.1.bn1.weight] shape:[(512,)].\n",
      "    val:[0.247 0.23  0.21  0.258 0.288]\n",
      "    --[True].\n",
      "[98] name:[module.layer4.1.bn1.bias] shape:[(512,)].\n",
      "    val:[-0.269 -0.243 -0.198 -0.25  -0.327]\n",
      "    --[True].\n",
      "[99] name:[module.layer4.1.conv2.weight] shape:[(512, 512, 3, 3)].\n",
      "    val:[0.002 0.009 0.004 0.002 0.008]\n",
      "    --[True].\n",
      "[100] name:[module.layer4.1.bn2.weight] shape:[(512,)].\n",
      "    val:[0.592 0.595 0.524 0.572 0.548]\n",
      "    --[True].\n",
      "[101] name:[module.layer4.1.bn2.bias] shape:[(512,)].\n",
      "    val:[-0.142 -0.179 -0.186 -0.113 -0.115]\n",
      "    --[True].\n",
      "[102] name:[module.layer4.2.conv1.weight] shape:[(512, 512, 3, 3)].\n",
      "    val:[0.021 0.028 0.021 0.049 0.059]\n",
      "    --[True].\n",
      "[103] name:[module.layer4.2.bn1.weight] shape:[(512,)].\n",
      "    val:[0.26  0.228 0.275 0.229 0.224]\n",
      "    --[True].\n",
      "[104] name:[module.layer4.2.bn1.bias] shape:[(512,)].\n",
      "    val:[-0.215 -0.164 -0.275 -0.147 -0.161]\n",
      "    --[True].\n",
      "[105] name:[module.layer4.2.conv2.weight] shape:[(512, 512, 3, 3)].\n",
      "    val:[0.042 0.035 0.04  0.032 0.017]\n",
      "    --[True].\n",
      "[106] name:[module.layer4.2.bn2.weight] shape:[(512,)].\n",
      "    val:[1.436 1.512 1.565 1.291 1.287]\n",
      "    --[True].\n",
      "[107] name:[module.layer4.2.bn2.bias] shape:[(512,)].\n",
      "    val:[0.122 0.129 0.193 0.133 0.098]\n",
      "    --[True].\n",
      "[108] name:[module.fc.weight] shape:[(18, 512)].\n",
      "    val:[-0.054 -0.072  0.001 -0.048 -0.083]\n",
      "    --[True].\n",
      "[109] name:[module.fc.bias] shape:[(18,)].\n",
      "    val:[ 0.017 -0.026  0.006 -0.042 -0.039]\n",
      "    --[True].\n",
      "Total number of parameters:[21,293,906].\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "n_param = 0\n",
    "for p_idx, (param_name, param) in enumerate(basemodel_resnet34.named_parameters()):\n",
    "    if param.requires_grad:\n",
    "        \n",
    "        #if param_name.startswith('module.fc') or param_name.startswith('module.layer4') or param_name.startswith('module.layer3'):\n",
    "        #    param.requires_grad = True  # Train\n",
    "        #else:\n",
    "        #    param.requires_grad = False # Freeze\n",
    "            \n",
    "        param_numpy = param.detach().cpu().numpy()\n",
    "        n_param += len(param_numpy.reshape(-1))\n",
    "        print (\"[%d] name:[%s] shape:[%s].\"%(p_idx,param_name,param_numpy.shape))\n",
    "        print (\"    val:%s\"%(param_numpy.reshape(-1)[:5]))\n",
    "        print(f\"    --[{param.requires_grad}].\")\n",
    "print (\"Total number of parameters:[%s].\"%(format(n_param,',d')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c067d0e-38c9-4ab8-baba-88cf8dcb8c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:54<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[0/50] training loss 0.003, training accuracy 0.070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.535, loss : 1.254, f1 score: 0.736 -- size(15)\n",
      "best acc : 0.535, best loss : 1.254, best f1 : 0.736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:29<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[1/50] training loss 0.002, training accuracy 0.078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.611, loss : 1.029, f1 score: 0.981 -- size(15)\n",
      "best acc : 0.611, best loss : 1.029, best f1 : 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:29<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[2/50] training loss 0.000, training accuracy 0.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.732, loss : 0.795, f1 score: 0.901 -- size(15)\n",
      "best acc : 0.732, best loss : 0.795, best f1 : 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:29<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[3/50] training loss 0.000, training accuracy 0.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.777, loss : 0.648, f1 score: 0.951 -- size(15)\n",
      "best acc : 0.777, best loss : 0.648, best f1 : 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:29<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[4/50] training loss 0.000, training accuracy 0.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.806, loss : 0.600, f1 score: 0.680 -- size(15)\n",
      "best acc : 0.806, best loss : 0.600, best f1 : 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:29<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[5/50] training loss 0.000, training accuracy 0.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.792, loss : 0.761, f1 score: 0.689 -- size(15)\n",
      "best acc : 0.806, best loss : 0.600, best f1 : 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:29<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[6/50] training loss 0.000, training accuracy 0.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.679, loss : 1.512, f1 score: 0.625 -- size(15)\n",
      "best acc : 0.806, best loss : 0.600, best f1 : 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:29<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[7/50] training loss 0.000, training accuracy 0.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.614, loss : 2.203, f1 score: 0.496 -- size(15)\n",
      "best acc : 0.806, best loss : 0.600, best f1 : 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:29<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[8/50] training loss 0.000, training accuracy 0.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.778, loss : 0.969, f1 score: 0.677 -- size(15)\n",
      "best acc : 0.806, best loss : 0.600, best f1 : 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:29<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[9/50] training loss 0.000, training accuracy 0.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.754, loss : 1.059, f1 score: 0.517 -- size(15)\n",
      "best acc : 0.806, best loss : 0.600, best f1 : 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:50<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[10/50] training loss 0.000, training accuracy 0.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.743, loss : 1.239, f1 score: 0.573 -- size(15)\n",
      "best acc : 0.806, best loss : 0.600, best f1 : 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:29<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[11/50] training loss 0.000, training accuracy 0.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.790, loss : 0.969, f1 score: 0.570 -- size(15)\n",
      "best acc : 0.806, best loss : 0.600, best f1 : 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:32<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[12/50] training loss 0.000, training accuracy 0.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.811, loss : 0.920, f1 score: 0.559 -- size(15)\n",
      "best acc : 0.811, best loss : 0.600, best f1 : 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:33<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[13/50] training loss 0.000, training accuracy 0.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.844, loss : 0.680, f1 score: 0.572 -- size(15)\n",
      "best acc : 0.844, best loss : 0.600, best f1 : 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:33<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[14/50] training loss 0.000, training accuracy 0.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.867, loss : 0.636, f1 score: 0.694 -- size(15)\n",
      "best acc : 0.867, best loss : 0.600, best f1 : 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:33<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[15/50] training loss 0.000, training accuracy 0.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.865, loss : 0.646, f1 score: 0.634 -- size(15)\n",
      "best acc : 0.867, best loss : 0.600, best f1 : 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:33<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[16/50] training loss 0.000, training accuracy 0.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.858, loss : 0.640, f1 score: 0.653 -- size(15)\n",
      "best acc : 0.867, best loss : 0.600, best f1 : 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:33<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[17/50] training loss 0.000, training accuracy 0.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.848, loss : 0.745, f1 score: 0.842 -- size(15)\n",
      "best acc : 0.867, best loss : 0.600, best f1 : 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:33<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[18/50] training loss 0.000, training accuracy 0.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.870, loss : 0.603, f1 score: 0.849 -- size(15)\n",
      "best acc : 0.870, best loss : 0.600, best f1 : 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:33<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[19/50] training loss 0.000, training accuracy 0.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.870, loss : 0.594, f1 score: 0.842 -- size(15)\n",
      "best acc : 0.870, best loss : 0.594, best f1 : 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:58<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[20/50] training loss 0.000, training accuracy 0.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.870, loss : 0.590, f1 score: 0.842 -- size(15)\n",
      "best acc : 0.870, best loss : 0.590, best f1 : 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:33<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[21/50] training loss 0.000, training accuracy 0.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.872, loss : 0.586, f1 score: 0.842 -- size(15)\n",
      "best acc : 0.872, best loss : 0.586, best f1 : 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:34<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[22/50] training loss 0.000, training accuracy 0.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.873, loss : 0.583, f1 score: 0.842 -- size(15)\n",
      "best acc : 0.873, best loss : 0.583, best f1 : 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:34<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[23/50] training loss 0.000, training accuracy 0.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.874, loss : 0.581, f1 score: 0.842 -- size(15)\n",
      "best acc : 0.874, best loss : 0.581, best f1 : 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:33<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[24/50] training loss 0.000, training accuracy 0.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.874, loss : 0.579, f1 score: 0.842 -- size(15)\n",
      "best acc : 0.874, best loss : 0.579, best f1 : 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:33<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[25/50] training loss 0.000, training accuracy 0.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.874, loss : 0.577, f1 score: 0.842 -- size(15)\n",
      "best acc : 0.874, best loss : 0.577, best f1 : 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:33<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[26/50] training loss 0.000, training accuracy 0.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.875, loss : 0.576, f1 score: 0.842 -- size(15)\n",
      "best acc : 0.875, best loss : 0.576, best f1 : 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:33<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[27/50] training loss 0.000, training accuracy 0.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.875, loss : 0.575, f1 score: 0.842 -- size(15)\n",
      "best acc : 0.875, best loss : 0.575, best f1 : 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:33<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[28/50] training loss 0.000, training accuracy 0.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.875, loss : 0.574, f1 score: 0.842 -- size(15)\n",
      "best acc : 0.875, best loss : 0.574, best f1 : 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:29<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[29/50] training loss 0.000, training accuracy 0.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.875, loss : 0.574, f1 score: 0.842 -- size(15)\n",
      "best acc : 0.875, best loss : 0.574, best f1 : 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:52<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[30/50] training loss 0.000, training accuracy 0.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.876, loss : 0.573, f1 score: 0.842 -- size(15)\n",
      "best acc : 0.876, best loss : 0.573, best f1 : 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:29<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[31/50] training loss 0.000, training accuracy 0.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.875, loss : 0.573, f1 score: 0.842 -- size(15)\n",
      "best acc : 0.876, best loss : 0.573, best f1 : 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:36<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[32/50] training loss 0.000, training accuracy 0.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.876, loss : 0.572, f1 score: 0.842 -- size(15)\n",
      "best acc : 0.876, best loss : 0.572, best f1 : 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:36<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[33/50] training loss 0.000, training accuracy 0.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.876, loss : 0.572, f1 score: 0.842 -- size(15)\n",
      "best acc : 0.876, best loss : 0.572, best f1 : 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:36<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[34/50] training loss 0.000, training accuracy 0.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.877, loss : 0.572, f1 score: 0.849 -- size(15)\n",
      "best acc : 0.877, best loss : 0.572, best f1 : 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:36<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[35/50] training loss 0.000, training accuracy 0.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.877, loss : 0.572, f1 score: 0.849 -- size(15)\n",
      "best acc : 0.877, best loss : 0.572, best f1 : 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:36<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[36/50] training loss 0.000, training accuracy 0.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.877, loss : 0.572, f1 score: 0.849 -- size(15)\n",
      "best acc : 0.877, best loss : 0.572, best f1 : 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:36<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[37/50] training loss 0.000, training accuracy 0.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.877, loss : 0.572, f1 score: 0.849 -- size(15)\n",
      "best acc : 0.877, best loss : 0.572, best f1 : 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:36<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[38/50] training loss 0.000, training accuracy 0.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.877, loss : 0.573, f1 score: 0.849 -- size(15)\n",
      "best acc : 0.877, best loss : 0.572, best f1 : 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:36<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[39/50] training loss 0.000, training accuracy 0.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.877, loss : 0.573, f1 score: 0.849 -- size(15)\n",
      "best acc : 0.877, best loss : 0.572, best f1 : 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [01:03<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[40/50] training loss 0.000, training accuracy 0.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.878, loss : 0.573, f1 score: 0.849 -- size(15)\n",
      "best acc : 0.878, best loss : 0.572, best f1 : 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:36<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[41/50] training loss 0.000, training accuracy 0.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.878, loss : 0.574, f1 score: 0.849 -- size(15)\n",
      "best acc : 0.878, best loss : 0.572, best f1 : 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:34<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[42/50] training loss 0.000, training accuracy 0.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.879, loss : 0.574, f1 score: 0.849 -- size(15)\n",
      "best acc : 0.879, best loss : 0.572, best f1 : 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:29<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[43/50] training loss 0.000, training accuracy 0.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.879, loss : 0.574, f1 score: 0.849 -- size(15)\n",
      "best acc : 0.879, best loss : 0.572, best f1 : 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:29<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[44/50] training loss 0.000, training accuracy 0.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.879, loss : 0.575, f1 score: 0.849 -- size(15)\n",
      "best acc : 0.879, best loss : 0.572, best f1 : 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:35<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[45/50] training loss 0.000, training accuracy 0.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.879, loss : 0.575, f1 score: 0.849 -- size(15)\n",
      "best acc : 0.879, best loss : 0.572, best f1 : 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:36<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[46/50] training loss 0.000, training accuracy 0.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:05<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.879, loss : 0.576, f1 score: 0.849 -- size(15)\n",
      "best acc : 0.879, best loss : 0.572, best f1 : 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:36<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[47/50] training loss 0.000, training accuracy 0.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:05<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.879, loss : 0.576, f1 score: 0.849 -- size(15)\n",
      "best acc : 0.879, best loss : 0.572, best f1 : 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:36<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[48/50] training loss 0.000, training accuracy 0.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:05<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.880, loss : 0.577, f1 score: 0.849 -- size(15)\n",
      "best acc : 0.880, best loss : 0.572, best f1 : 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:36<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[49/50] training loss 0.000, training accuracy 0.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.880, loss : 0.577, f1 score: 0.849 -- size(15)\n",
      "best acc : 0.880, best loss : 0.572, best f1 : 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_val_acc = 0\n",
    "best_val_loss = np.inf\n",
    "patience = 10\n",
    "cur_count = 0\n",
    "\n",
    "f1 = F1Score(num_classes=class_num, average='macro').to(device)\n",
    "best_f1_score = 0\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for epoch in range(NUM_EPOCH):\n",
    "    basemodel_resnet34.train()\n",
    "    loss_value = 0\n",
    "    matches = 0\n",
    "    for train_batch in tqdm(train_dataloader_mask):\n",
    "        inputs, labels = train_batch\n",
    "        \n",
    "        #plt.imshow(transforms.ToPILImage()(inputs[0]))\n",
    "        #plt.show()\n",
    "        #continue\n",
    "        \n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outs = basemodel_resnet34(inputs)\n",
    "        preds = torch.argmax(outs, dim=-1)\n",
    "        loss = criterion(outs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            torch.save(basemodel_resnet34, '../checkpoint/resnet34_with_detect/checkpoint_ep_%d.pth'% epoch)\n",
    "        \n",
    "        loss_value += loss.item()\n",
    "        matches += (preds == labels).sum().item()\n",
    "        \n",
    "        train_loss = loss_value / batch_size\n",
    "        train_acc = matches / batch_size\n",
    "        \n",
    "        loss_value = 0\n",
    "        matches = 0\n",
    "    print(f\"epoch[{epoch}/{NUM_EPOCH}] training loss {train_loss:.3f}, training accuracy {train_acc:.3f}\")\n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        basemodel_resnet34.eval()\n",
    "        val_loss_items = []\n",
    "        val_acc_items = []\n",
    "        for val_batch in tqdm(val_dataloader_mask):\n",
    "            inputs, labels = val_batch\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outs = basemodel_resnet34(inputs)\n",
    "            preds = torch.argmax(outs, dim=-1)\n",
    "            \n",
    "            loss_item = criterion(outs, labels).item()\n",
    "            acc_item = (labels==preds).sum().item()\n",
    "            val_loss_items.append(loss_item)\n",
    "            val_acc_items.append(acc_item)\n",
    "            \n",
    "        val_loss = np.sum(val_loss_items) / len(val_dataloader_mask)\n",
    "        val_acc = np.sum(val_acc_items) / len(mask_val_set)\n",
    "\n",
    "        f1_score = f1(outs, labels)\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            \n",
    "        if f1_score > best_f1_score:\n",
    "            best_f1_score = f1_score\n",
    "#             cur_count = 0\n",
    "            torch.save(basemodel_resnet34, '../checkpoint/resnet34_with_detect/checkpoint_best.pth')\n",
    "#         else:\n",
    "#             cur_count += 1\n",
    "#             if cur_count >= patience:\n",
    "#                 print(\"Early Stopping!\")\n",
    "#                 break\n",
    "            \n",
    "            \n",
    "        print(f\"[val] acc : {val_acc:.3f}, loss : {val_loss:.3f}, f1 score: {f1_score:.3f} -- size({len(val_dataloader_mask)})\")\n",
    "        print(f\"best acc : {best_val_acc:.3f}, best loss : {best_val_loss:.3f}, best f1 : {best_f1_score:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
