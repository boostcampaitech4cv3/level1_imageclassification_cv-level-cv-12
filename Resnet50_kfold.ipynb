{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c84b6b-e562-4293-b364-adaf3cc651ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2358d4-dbaf-4af8-a611-3f6a2e35dae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPUtil\n",
    "GPUtil.showUtilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1d65a3-78de-4b01-a862-e6bd4c7ef135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, sampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import os\n",
    "from torchmetrics import F1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15beaba-39cc-48da-8165-9f2abc16322a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/opt/ml/input/data')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3beb99-f9c7-4026-989a-cbaa8de1f632",
   "metadata": {},
   "outputs": [],
   "source": [
    "!find . -regex \".*\\.\\_[a-zA-Z0-9._]+\" -delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8d19de-5a8e-454f-a22b-129e94792395",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 12\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f69f93c-5675-433f-8a88-7bf8e411d51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir_path = '/opt/ml/input/data/train/'\n",
    "train_image_path = '/opt/ml/input/data/train/images/'\n",
    "\n",
    "dt_train = pd.read_csv(train_dir_path+'train.csv')\n",
    "dt_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3377e12b-fd28-4837-a749-bba0d75ff944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_age_range(age):\n",
    "    if age < 30:\n",
    "        return 0\n",
    "    elif 30 <= age < 60:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962b5a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file, gender, age):\n",
    "    if 'normal'in file:\n",
    "        # Not Wear\n",
    "        if gender =='male':\n",
    "            if age < 30: \n",
    "                return 12\n",
    "            elif age < 60:\n",
    "                return 13\n",
    "            else:\n",
    "                return 14\n",
    "        else: # female\n",
    "            if age < 30:\n",
    "                return 15\n",
    "            elif age < 60:\n",
    "                return 16\n",
    "            else:\n",
    "                return 17\n",
    "    elif 'incorrect' in file:\n",
    "        # Incorrect\n",
    "        if gender == 'male':\n",
    "            if age < 30: \n",
    "                return 6\n",
    "            elif age < 60:\n",
    "                return 7\n",
    "            else:\n",
    "                return 8\n",
    "        else: # female\n",
    "            if age < 30:\n",
    "                return 9\n",
    "            elif age < 60:\n",
    "                return 10\n",
    "            else:\n",
    "                return 11\n",
    "    else:\n",
    "        # Wear\n",
    "        if gender == 'male':\n",
    "            if age < 30: \n",
    "                return 0\n",
    "            elif age < 60:\n",
    "                return 1\n",
    "            else:\n",
    "                return 2\n",
    "        else: # female\n",
    "            if age < 30:\n",
    "                return 3\n",
    "            elif age < 60:\n",
    "                return 4\n",
    "            else:\n",
    "                return 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9757722a-75bc-42f9-a3ff-3fca7d10cb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_train['age_range'] = dt_train['age'].apply(lambda x : get_age_range(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63f5dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_train['label'] = -1\n",
    "\n",
    "for index, row in dt_train.iterrows():\n",
    "    for file in os.listdir(os.path.join(train_dir_path, f\"images/{row['path']}\")):\n",
    "        #print(get_label(file, row['gender'], row['age']))\n",
    "        dt_train.at[index, 'label'] = get_label(file, row['gender'], row['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95f3599-8a5f-4815-91d5-673118deaced",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c164652-b2c8-4340-b55d-6ba9108ad9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_idx, valid_idx = train_test_split(np.arange(len(dt_train)),\n",
    "#                                        test_size=0.2,\n",
    "#                                        shuffle=True,\n",
    "#                                        stratify=dt_train['age_range'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53d195f-6e0c-4af7-a558-30ad3481e8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_image = []\n",
    "# train_label = []\n",
    "\n",
    "# for idx in train_idx:\n",
    "#     path = dt_train.iloc[idx]['path']\n",
    "#     for file_name in [i for i in os.listdir(train_image_path+path) if i[0] != '.']:\n",
    "#         train_image.append(train_image_path+path+'/'+file_name)\n",
    "#         train_label.append((path.split('_')[1], path.split('_')[3], file_name.split('.')[0]))                                 \n",
    "\n",
    "# print(train_label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5b59fc-3b23-4b0a-a747-a3197958daa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_image = []\n",
    "# valid_label = []\n",
    "\n",
    "# for idx in valid_idx:\n",
    "#     path = dt_train.iloc[idx]['path']\n",
    "#     for file_name in [i for i in os.listdir(train_image_path+path) if i[0] != '.']:\n",
    "#         valid_image.append(train_image_path+path+'/'+file_name)\n",
    "#         valid_label.append((path.split('_')[1], path.split('_')[3], file_name.split('.')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ee24fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "def get_distribution(y_vals):\n",
    "    y_distr = Counter(y_vals)\n",
    "    y_vals_sum = sum(y_distr.values())\n",
    "    return [f'{y_distr[i] / y_vals_sum:.2%}' for i in range(np.max(y_vals) + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6485a764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "groups = np.array(dt_train.id.values)\n",
    "\n",
    "distrs = [get_distribution(dt_train.label)]\n",
    "index = ['training set']\n",
    "\n",
    "train_idx, valid_idx = [], []\n",
    "train_groups, valid_groups = [], []\n",
    "train_y, valid_y = [], []\n",
    "num_fold = 4\n",
    "\n",
    "# 4개의 폴드 세트로 분리하는 StratifiedKFold 세트 생성\n",
    "skfold = StratifiedKFold(n_splits=num_fold, shuffle=True, random_state=2022)\n",
    "\n",
    "for fold_index, (train_index, valid_index) in enumerate(skfold.split(X=dt_train.id, y=dt_train.label)):\n",
    "    # print(\"%s %s\" % (train_index, test_index))\n",
    "    print(f\"Fold {fold_index}, Training set : {len(train_index)}, Test set : {len(valid_index)} \")\n",
    "    train_idx.append(train_index)\n",
    "    valid_idx.append(valid_index)\n",
    "    train_y.append(dt_train.label[train_index])\n",
    "    valid_y.append(dt_train.label[valid_index])\n",
    "    train_groups.append(groups[train_index])\n",
    "    valid_groups.append(groups[valid_index])\n",
    "\n",
    "    distrs.append(get_distribution(train_y[-1]))\n",
    "    index.append(f\"Fold {fold_index} - Training set\")\n",
    "    distrs.append(get_distribution(valid_y[-1]))\n",
    "    index.append(f\"Fold {fold_index} - Testing set\")\n",
    "\n",
    "    print(\"train_groups: \", train_groups)\n",
    "    print(\"train_y: \",train_y)\n",
    "    print(\"test_groups: \",valid_groups)\n",
    "    print(\"test_y: \",valid_y)\n",
    "    print(\"-------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acb491c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Distribution per class:')\n",
    "pd.DataFrame(distrs, index=index, columns=[f'Label {l}' for l in range(np.max(train_y) + 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98de1eb4-55d4-41ba-8541-70fff9bb011e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_enc(x):\n",
    "    def gender(i):\n",
    "        if i == 'male':\n",
    "            return 0\n",
    "        elif i == 'female':\n",
    "            return 3\n",
    "    def age(j):\n",
    "        j = int(j)\n",
    "        if j < 30:\n",
    "            return 0\n",
    "        elif j >= 30 and j < 60:\n",
    "            return 1\n",
    "        elif j >= 60:\n",
    "            return 2\n",
    "    def mask(k):\n",
    "        if k == 'normal':\n",
    "            return 12\n",
    "        elif 'incorrect' in k:\n",
    "            return 6\n",
    "        else:\n",
    "            return 0\n",
    "    return gender(x[0]) + age(x[1]) + mask(x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943d0388-3736-4b6b-a624-0213148616f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = pd.Series(train_image)\n",
    "# train_label = pd.Series(train_label)\n",
    "\n",
    "# valid_data = pd.Series(valid_image)\n",
    "# valid_label = pd.Series(valid_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551c673c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_Mask(Dataset):\n",
    "    def __init__(self, data, label, encoding=True, midcrop=True, transform=None):\n",
    "        self.encoding = encoding\n",
    "        self.midcrop = midcrop\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.transform = transform\n",
    "        \n",
    "        if encoding:\n",
    "            self.label = self.label.apply(onehot_enc)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X = cv2.cvtColor(cv2.imread(self.data[idx]), cv2.COLOR_BGR2RGB)\n",
    "        y = self.label[idx]\n",
    "        \n",
    "        if self.midcrop:\n",
    "            X = X[70:420, 17:367]\n",
    "        \n",
    "        if self.transform:\n",
    "            return self.transform(X), y\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0e4cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_class_weights(labels, class_num):\n",
    "    print(\"Labels shape:\\n\", labels.shape)\n",
    "    print(\"Given labels:\\n\", labels)\n",
    "\n",
    "    labels = labels.apply(lambda x : x % class_num)\n",
    "\n",
    "    labels = np.array(labels)\n",
    "    class_weights = np.zeros_like(labels) \n",
    "    \n",
    "    _, counts = np.unique(labels, return_counts=True)\n",
    "    # 각 class가 몇 번 등장하는지 count\n",
    "\n",
    "    print(\"Labels:\\n\", labels)\n",
    "    print(\"Label count:\\n\", counts)\n",
    "\n",
    "    for cls in range(class_num):\n",
    "        class_weights = np.where(labels == cls, 1/counts[cls], class_weights)\n",
    "        # label이 class에 해당하면 count의 역수 적용\n",
    "    return class_weights\n",
    "\n",
    "class_num = 18\n",
    "age_class_num = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe3b5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet50(pretrained=True)\n",
    "print('필요 입력 채널 개수', model.conv1.weight.shape[1])\n",
    "print('네트워크 출력 채널 개수', model.fc.weight.shape[0])\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9899a97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "model.fc = nn.Linear(in_features=2048, out_features=class_num, bias=True)\n",
    "nn.init.xavier_uniform_(model.fc.weight)\n",
    "stdv = 1. / math.sqrt(model.fc.weight.size(1))\n",
    "model.fc.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "print('필요 입력 채널 개수', model.conv1.weight.shape[1])\n",
    "print('네트워크 출력 채널 개수', model.fc.weight.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cc905d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"using {device}\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "LEARNING_RATE = 0.0001\n",
    "NUM_EPOCH = 15\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b82bd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(fold_idx, train_dataloader_mask, val_dataloader_mask):\n",
    "    best_val_acc = 0\n",
    "    best_val_loss = np.inf\n",
    "    patience = 5\n",
    "    cur_count = 0\n",
    "\n",
    "    f1 = F1Score(num_classes=class_num, average='macro').to(device)\n",
    "    best_f1_score = 0\n",
    "\n",
    "    for epoch in range(NUM_EPOCH):\n",
    "        model.train()\n",
    "        loss_value = 0\n",
    "        matches = 0\n",
    "        for train_batch in train_dataloader_mask:\n",
    "            inputs, labels = train_batch\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outs = model(inputs)\n",
    "            preds = torch.argmax(outs, dim=-1)\n",
    "            loss = criterion(outs, labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                torch.save(model, '/opt/ml/checkpoint/resnet50_kfold/checkpoint_%dfold_ep%d.pt'% fold_idx, epoch)\n",
    "            \n",
    "            loss_value += loss.item()\n",
    "            matches += (preds == labels).sum().item()\n",
    "\n",
    "        train_loss = loss_value / batch_size\n",
    "        train_acc = matches / batch_size\n",
    "\n",
    "        loss_value = 0\n",
    "        matches = 0\n",
    "\n",
    "        print(f\"epoch[{epoch}/{NUM_EPOCH}] training loss {train_loss:.3f}, training accuracy {train_acc:.3f}\")\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            val_loss_items = []\n",
    "            val_acc_items = []\n",
    "            f1_score = 0\n",
    "            for val_batch in val_dataloader_mask:\n",
    "                inputs, labels = val_batch\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                outs = model(inputs)\n",
    "                preds = torch.argmax(outs, dim=-1)\n",
    "                \n",
    "                loss_item = criterion(outs, labels).item()\n",
    "                acc_item = (labels==preds).sum().item()\n",
    "                val_loss_items.append(loss_item)\n",
    "                val_acc_items.append(acc_item)\n",
    "                f1_score += f1(outs, labels)\n",
    "                \n",
    "            val_loss = np.sum(val_loss_items) / len(val_dataloader_mask)\n",
    "            val_acc = np.sum(val_acc_items) / len(val_dataloader_mask.dataset)\n",
    "            f1_score /= len(val_dataloader_mask)\n",
    "            \n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "\n",
    "            if f1_score > best_f1_score:\n",
    "                best_f1_score = f1_score\n",
    "                cur_count = 0\n",
    "                torch.save(model, '/opt/ml/checkpoint/resnet50_kfold/checkpoint_best.pt')\n",
    "                print(\"Update checkpoint!!!\")\n",
    "            else:\n",
    "                cur_count += 1\n",
    "                if cur_count >= patience:\n",
    "                    print(\"Early Stopping!\")\n",
    "                    break\n",
    "            print(f\"[val] acc : {val_acc:.3f}, loss : {val_loss:.3f}, f1 score: {f1_score:.3f}\")\n",
    "            print(f\"best acc : {best_val_acc:.3f}, best loss : {best_val_loss:.3f}, best f1 : {best_f1_score:.3f}\")\n",
    "\n",
    "    return best_val_acc, best_val_loss, best_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440c4706",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_acc, best_val_loss, best_f1_score = 0, 0, 0\n",
    "\n",
    "for idx in range(num_fold):\n",
    "    train_image = []\n",
    "    for i in train_idx[idx]:\n",
    "        path = dt_train.iloc[i]['path']\n",
    "        for file_name in [i for i in os.listdir(train_image_path+path) if i[0] != '.']:\n",
    "            train_image.append(train_image_path+path+'/'+file_name)\n",
    "\n",
    "    valid_image = []\n",
    "    for i in valid_idx[idx]:\n",
    "        path = dt_train.iloc[i]['path']\n",
    "        for file_name in [i for i in os.listdir(train_image_path+path) if i[0] != '.']:\n",
    "            train_image.append(train_image_path+path+'/'+file_name)\n",
    "\n",
    "    train_data = pd.Series(train_image)\n",
    "    train_label = pd.Series(train_y[idx])\n",
    "\n",
    "    valid_data = pd.Series(valid_image)\n",
    "    valid_label = pd.Series(valid_y[idx])\n",
    "\n",
    "    mask_train_set = Dataset_Mask(data=train_data, label=train_label, encoding=False, transform = transforms.Compose([\n",
    "                                transforms.ToTensor()\n",
    "                            ]))\n",
    "\n",
    "    mask_val_set = Dataset_Mask(data=valid_data, label=valid_label, encoding=False, transform = transforms.Compose([\n",
    "                                    transforms.ToTensor()\n",
    "                                ]))\n",
    "\n",
    "    # print(f'training data size : {len(mask_train_set)}')\n",
    "    # print(f'validation data size : {len(mask_val_set)}')\n",
    "    \n",
    "    class_weights = make_class_weights(mask_train_set.label, age_class_num)\n",
    "\n",
    "    sampler = sampler.WeightedRandomSampler(weights=class_weights, num_samples=len(class_weights))\n",
    "\n",
    "    train_dataloader_mask = DataLoader(dataset = mask_train_set, batch_size=batch_size, sampler=sampler, num_workers=2)\n",
    "    val_dataloader_mask = DataLoader(dataset = mask_val_set, batch_size=batch_size, num_workers=2)\n",
    "\n",
    "    cur_val_acc, cur_val_loss, cur_f1_score = train(idx, train_dataloader_mask, val_dataloader_mask)\n",
    "\n",
    "    best_val_acc += cur_val_acc\n",
    "    best_val_loss += cur_val_loss\n",
    "    best_f1_score += cur_f1_score\n",
    "\n",
    "    print(\"--------------------------------------------------------------------------------------------------------------------\")\n",
    "    print(f\"{idx}'th FOLD - best acc : {cur_val_acc:.3f}, best loss : {cur_val_loss:.3f}, best f1 : {cur_f1_score:.3f}\")\n",
    "    print(\"--------------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(f\"****FINAL - best acc : {best_val_acc/num_fold:.3f}, best loss : {best_val_loss/num_fold:.3f}, best f1 : {best_f1_score/num_fold:.3f}*****\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afda23d0-6ad9-408b-99c9-705ae5fd8347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "test_dir_path = '/opt/ml/input/data/eval/'\n",
    "test_image_path = '/opt/ml/input/data/eval/images/'\n",
    "\n",
    "model = torch.load('/opt/ml/checkpoint/resnet50_kfold/checkpoint_best.pt')\n",
    "submission = pd.read_csv(test_dir_path+'info.csv')\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566c2df1-a083-4e27-a655-f2c73d15f762",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = [os.path.join(test_image_path, img_id) for img_id in submission.ImageID]\n",
    "test_image = pd.Series(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c14322-45a8-40a5-aded-f335204484b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test_Dataset(Dataset):\n",
    "    def __init__(self, midcrop=True, transform=None):\n",
    "        self.midcrop = midcrop\n",
    "        self.data = test_image\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(test_image)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.cvtColor(cv2.imread(self.data[idx]), cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.midcrop:\n",
    "            img = img[64:448]\n",
    "            \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138db932-cc09-4f85-89d8-e7485659f7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Test_Dataset(transform = transforms.Compose([\n",
    "                            transforms.ToTensor()\n",
    "                        ]))\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "# 모델을 정의합니다. (학습한 모델이 있다면 torch.load로 모델을 불러주세요!)\n",
    "device = torch.device('cuda')\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "all_predictions = []\n",
    "for images in tqdm(loader):\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        pred = model(images)\n",
    "        pred = pred.argmax(dim=-1)\n",
    "        all_predictions.extend(pred.cpu().numpy())\n",
    "submission['ans'] = all_predictions\n",
    "\n",
    "# 제출할 파일을 저장합니다.\n",
    "submission.to_csv(os.path.join(test_dir_path, 'submission_resnet50_kfold.csv'), index=False)\n",
    "print('test inference is done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
