{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1c84b6b-e562-4293-b364-adaf3cc651ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea2358d4-dbaf-4af8-a611-3f6a2e35dae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 36% |\n"
     ]
    }
   ],
   "source": [
    "import GPUtil\n",
    "GPUtil.showUtilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b1d65a3-78de-4b01-a862-e6bd4c7ef135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "import os\n",
    "from torchmetrics import F1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d15beaba-39cc-48da-8165-9f2abc16322a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/ml/input/data'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('/opt/ml/input/data')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b3beb99-f9c7-4026-989a-cbaa8de1f632",
   "metadata": {},
   "outputs": [],
   "source": [
    "!find . -regex \".*\\.\\_[a-zA-Z0-9._]+\" -delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa8d19de-5a8e-454f-a22b-129e94792395",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 12\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f69f93c-5675-433f-8a88-7bf8e411d51c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>45</td>\n",
       "      <td>000001_female_Asian_45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000002</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>52</td>\n",
       "      <td>000002_female_Asian_52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000004</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>54</td>\n",
       "      <td>000004_male_Asian_54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000005</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>58</td>\n",
       "      <td>000005_female_Asian_58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000006</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>59</td>\n",
       "      <td>000006_female_Asian_59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2695</th>\n",
       "      <td>006954</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19</td>\n",
       "      <td>006954_male_Asian_19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2696</th>\n",
       "      <td>006955</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19</td>\n",
       "      <td>006955_male_Asian_19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2697</th>\n",
       "      <td>006956</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19</td>\n",
       "      <td>006956_male_Asian_19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2698</th>\n",
       "      <td>006957</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>20</td>\n",
       "      <td>006957_male_Asian_20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2699</th>\n",
       "      <td>006959</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19</td>\n",
       "      <td>006959_male_Asian_19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2700 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  gender   race  age                    path\n",
       "0     000001  female  Asian   45  000001_female_Asian_45\n",
       "1     000002  female  Asian   52  000002_female_Asian_52\n",
       "2     000004    male  Asian   54    000004_male_Asian_54\n",
       "3     000005  female  Asian   58  000005_female_Asian_58\n",
       "4     000006  female  Asian   59  000006_female_Asian_59\n",
       "...      ...     ...    ...  ...                     ...\n",
       "2695  006954    male  Asian   19    006954_male_Asian_19\n",
       "2696  006955    male  Asian   19    006955_male_Asian_19\n",
       "2697  006956    male  Asian   19    006956_male_Asian_19\n",
       "2698  006957    male  Asian   20    006957_male_Asian_20\n",
       "2699  006959    male  Asian   19    006959_male_Asian_19\n",
       "\n",
       "[2700 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir_path = '/opt/ml/input/data/train/'\n",
    "train_image_path = '/opt/ml/input/data/train/images/'\n",
    "\n",
    "dt_train = pd.read_csv(train_dir_path+'train.csv')\n",
    "dt_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3377e12b-fd28-4837-a749-bba0d75ff944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_age_range(age):\n",
    "    if age < 30:\n",
    "        return 0\n",
    "    elif 30 <= age < 60:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9757722a-75bc-42f9-a3ff-3fca7d10cb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_train['age_range'] = dt_train['age'].apply(lambda x : get_age_range(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a95f3599-8a5f-4815-91d5-673118deaced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>path</th>\n",
       "      <th>age_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>45</td>\n",
       "      <td>000001_female_Asian_45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000002</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>52</td>\n",
       "      <td>000002_female_Asian_52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000004</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>54</td>\n",
       "      <td>000004_male_Asian_54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000005</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>58</td>\n",
       "      <td>000005_female_Asian_58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000006</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>59</td>\n",
       "      <td>000006_female_Asian_59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2695</th>\n",
       "      <td>006954</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19</td>\n",
       "      <td>006954_male_Asian_19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2696</th>\n",
       "      <td>006955</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19</td>\n",
       "      <td>006955_male_Asian_19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2697</th>\n",
       "      <td>006956</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19</td>\n",
       "      <td>006956_male_Asian_19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2698</th>\n",
       "      <td>006957</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>20</td>\n",
       "      <td>006957_male_Asian_20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2699</th>\n",
       "      <td>006959</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19</td>\n",
       "      <td>006959_male_Asian_19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2700 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  gender   race  age                    path  age_range\n",
       "0     000001  female  Asian   45  000001_female_Asian_45          1\n",
       "1     000002  female  Asian   52  000002_female_Asian_52          1\n",
       "2     000004    male  Asian   54    000004_male_Asian_54          1\n",
       "3     000005  female  Asian   58  000005_female_Asian_58          1\n",
       "4     000006  female  Asian   59  000006_female_Asian_59          1\n",
       "...      ...     ...    ...  ...                     ...        ...\n",
       "2695  006954    male  Asian   19    006954_male_Asian_19          0\n",
       "2696  006955    male  Asian   19    006955_male_Asian_19          0\n",
       "2697  006956    male  Asian   19    006956_male_Asian_19          0\n",
       "2698  006957    male  Asian   20    006957_male_Asian_20          0\n",
       "2699  006959    male  Asian   19    006959_male_Asian_19          0\n",
       "\n",
       "[2700 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1d903c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.0+cu117'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c164652-b2c8-4340-b55d-6ba9108ad9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, valid_idx = train_test_split(np.arange(len(dt_train)),\n",
    "                                       test_size=0.2,\n",
    "                                       shuffle=True,\n",
    "                                       stratify=dt_train['age_range'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c53d195f-6e0c-4af7-a558-30ad3481e8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image = []\n",
    "train_label = []\n",
    "\n",
    "for idx in train_idx:\n",
    "    path = dt_train.iloc[idx]['path']\n",
    "    for file_name in [i for i in os.listdir(train_image_path+path) if i[0] != '.']:\n",
    "        train_image.append(train_image_path+path+'/'+file_name)\n",
    "        train_label.append((path.split('_')[1], path.split('_')[3], file_name.split('.')[0]))                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d5b59fc-3b23-4b0a-a747-a3197958daa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_image = []\n",
    "valid_label = []\n",
    "\n",
    "for idx in valid_idx:\n",
    "    path = dt_train.iloc[idx]['path']\n",
    "    for file_name in [i for i in os.listdir(train_image_path+path) if i[0] != '.']:\n",
    "        valid_image.append(train_image_path+path+'/'+file_name)\n",
    "        valid_label.append((path.split('_')[1], path.split('_')[3], file_name.split('.')[0]))                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98de1eb4-55d4-41ba-8541-70fff9bb011e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_enc(x):\n",
    "    def gender(i):\n",
    "        if i == 'male':\n",
    "            return 0\n",
    "        elif i == 'female':\n",
    "            return 3\n",
    "    def age(j):\n",
    "        j = int(j)\n",
    "        if j < 30:\n",
    "            return 0\n",
    "        elif j >= 30 and j < 60:\n",
    "            return 1\n",
    "        elif j >= 60:\n",
    "            return 2\n",
    "    def mask(k):\n",
    "        if k == 'normal':\n",
    "            return 12\n",
    "        elif 'incorrect' in k:\n",
    "            return 6\n",
    "        else:\n",
    "            return 0\n",
    "    return gender(x[0]) + age(x[1]) + mask(x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "694474c7-7175-40e6-b071-e50218629f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sr_data = pd.Series(whole_image_path)\n",
    "# sr_label = pd.Series(whole_target_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "943d0388-3736-4b6b-a624-0213148616f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.Series(train_image)\n",
    "train_label = pd.Series(train_label)\n",
    "\n",
    "valid_data = pd.Series(valid_image)\n",
    "valid_label = pd.Series(valid_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2cd7b29-5f03-444e-b781-902ca74f2085",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_Mask(Dataset):\n",
    "    def __init__(self, data, label, encoding=True, midcrop=True, transform=None):\n",
    "        self.encoding = encoding\n",
    "        self.midcrop = midcrop\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.transform = transform\n",
    "        \n",
    "        if encoding:\n",
    "            self.label = self.label.apply(onehot_enc)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X = cv2.cvtColor(cv2.imread(self.data[idx]), cv2.COLOR_BGR2RGB)\n",
    "        y = self.label[idx]\n",
    "        \n",
    "        if self.midcrop:\n",
    "            X = X[70:420, 17:367]\n",
    "        \n",
    "        if self.transform:\n",
    "            return self.transform(X), y\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2a22aff-e634-4f15-877c-752d450d01da",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_train_set = Dataset_Mask(data=train_data, label=train_label, transform = transforms.Compose([\n",
    "                                transforms.ToTensor()\n",
    "                            ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e78516b2-b620-495c-bd6f-81baa034e3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_val_set = Dataset_Mask(data=valid_data, label=valid_label, transform = transforms.Compose([\n",
    "                                transforms.ToTensor()\n",
    "                            ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0989b05b-41b0-4a8f-9987-f062b7ad2bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_image = [mask_train_set[i][1] for i in range(len(mask_train_set))]\n",
    "# v_image = [mask_val_set[i][1] for i in range(len(mask_val_set))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09085d73-8a39-434b-bab3-9da358c5dde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_df = pd.DataFrame(t_image, columns=['counts'])\n",
    "# v_df = pd.DataFrame(v_image, columns=['counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7da846b8-9898-43ce-8a29-dc44483a71e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# sns.countplot(x='counts', data=t_df, ax=axes[0])\n",
    "# axes[0].set_xlabel(\"train set labels\")\n",
    "# sns.countplot(x='counts', data=v_df, ax=axes[1])\n",
    "# axes[1].set_xlabel(\"valid set labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff343e87-8482-4c01-abca-593a1d433226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size : 15120\n",
      "validation data size : 3780\n"
     ]
    }
   ],
   "source": [
    "print(f'training data size : {len(mask_train_set)}')\n",
    "print(f'validation data size : {len(mask_val_set)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0612969-f203-4b93-8607-9b6f291be475",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataloader_mask = DataLoader(dataset = mask_train_set, batch_size=batch_size, num_workers=2)\n",
    "val_dataloader_mask = DataLoader(dataset = mask_val_set, batch_size=batch_size, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af71a4ef-a137-47b0-af94-eebedaa36014",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "필요 입력 채널 개수 3\n",
      "네트워크 출력 채널 개수 1000\n",
      "EfficientNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2dNormActivation(\n",
      "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): SiLU(inplace=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (2): Conv2dNormActivation(\n",
      "            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n",
      "      )\n",
      "      (1): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
      "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n",
      "      )\n",
      "      (1): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n",
      "      )\n",
      "      (1): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n",
      "      )\n",
      "      (2): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
      "      )\n",
      "      (1): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
      "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n",
      "      )\n",
      "      (2): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
      "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
      "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n",
      "      )\n",
      "      (1): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n",
      "      )\n",
      "      (2): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n",
      "      )\n",
      "      (3): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
      "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (8): Conv2dNormActivation(\n",
      "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): SiLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.2, inplace=True)\n",
      "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.efficientnet_b0(weights=torchvision.models.EfficientNet_B0_Weights)\n",
    "print('필요 입력 채널 개수', model.features[0][0].weight.shape[1])\n",
    "print('네트워크 출력 채널 개수', model.classifier[1].weight.shape[0])\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "11357fc4-548b-452e-bbd8-e60ef6261308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "필요 입력 채널 개수 3\n",
      "네트워크 출력 채널 개수 18\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "class_num = 18\n",
    "model.classifier[1] = nn.Linear(in_features=1280, out_features=class_num, bias=True)\n",
    "nn.init.xavier_uniform_(model.classifier[1].weight)\n",
    "stdv = 1. / math.sqrt(model.classifier[1].weight.size(1))\n",
    "model.classifier[1].bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "print('필요 입력 채널 개수', model.features[0][0].weight.shape[1])\n",
    "print('네트워크 출력 채널 개수', model.classifier[1].weight.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a1a2262-f820-4294-8086-3a48a5e5d686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"using {device}\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "LEARNING_RATE = 0.0001\n",
    "NUM_EPOCH = 50\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "64a36f92-aad5-4bbb-a920-29d50f0f058b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] name:[features.0.0.weight] shape:[(32, 3, 3, 3)].\n",
      "    val:[ 0.122  0.656  0.457 -0.111 -0.61 ]\n",
      "[1] name:[features.0.1.weight] shape:[(32,)].\n",
      "    val:[ 1.894  1.682  2.791 10.844  1.386]\n",
      "[2] name:[features.0.1.bias] shape:[(32,)].\n",
      "    val:[2.481 2.348 3.165 1.48  2.608]\n",
      "[3] name:[features.1.0.block.0.0.weight] shape:[(32, 1, 3, 3)].\n",
      "    val:[-0.023  0.01  -0.003 -0.045 -0.227]\n",
      "[4] name:[features.1.0.block.0.1.weight] shape:[(32,)].\n",
      "    val:[1.839 1.471 4.132 5.941 2.181]\n",
      "[5] name:[features.1.0.block.0.1.bias] shape:[(32,)].\n",
      "    val:[ 1.692  2.38  -2.441 -0.459  8.766]\n",
      "[6] name:[features.1.0.block.1.fc1.weight] shape:[(8, 32, 1, 1)].\n",
      "    val:[-0.1   -0.053  0.254  0.192 -0.118]\n",
      "[7] name:[features.1.0.block.1.fc1.bias] shape:[(8,)].\n",
      "    val:[-1.219 -0.13  -1.247 -1.099 -1.75 ]\n",
      "[8] name:[features.1.0.block.1.fc2.weight] shape:[(32, 8, 1, 1)].\n",
      "    val:[-0.031  0.042  0.055  0.108  0.068]\n",
      "[9] name:[features.1.0.block.1.fc2.bias] shape:[(32,)].\n",
      "    val:[ 1.822  4.064 -0.54  -0.121  3.505]\n",
      "[10] name:[features.1.0.block.2.0.weight] shape:[(16, 32, 1, 1)].\n",
      "    val:[ 0.343 -0.018 -0.199  0.149 -0.074]\n",
      "[11] name:[features.1.0.block.2.1.weight] shape:[(16,)].\n",
      "    val:[6.415 6.134 6.251 6.586 5.384]\n",
      "[12] name:[features.1.0.block.2.1.bias] shape:[(16,)].\n",
      "    val:[-0.002 -0.007 -0.001  0.     0.008]\n",
      "[13] name:[features.2.0.block.0.0.weight] shape:[(96, 16, 1, 1)].\n",
      "    val:[ 1.042 -0.015 -0.052  0.244 -0.421]\n",
      "[14] name:[features.2.0.block.0.1.weight] shape:[(96,)].\n",
      "    val:[7.764 1.494 0.243 1.89  8.215]\n",
      "[15] name:[features.2.0.block.0.1.bias] shape:[(96,)].\n",
      "    val:[ 1.672  0.733  1.481  2.571 -0.721]\n",
      "[16] name:[features.2.0.block.1.0.weight] shape:[(96, 1, 3, 3)].\n",
      "    val:[ 0.023 -0.031  0.021 -0.101 -0.417]\n",
      "[17] name:[features.2.0.block.1.1.weight] shape:[(96,)].\n",
      "    val:[5.833 3.641 8.68  8.024 7.314]\n",
      "[18] name:[features.2.0.block.1.1.bias] shape:[(96,)].\n",
      "    val:[ 3.812  4.023 -0.055 -0.108 -0.559]\n",
      "[19] name:[features.2.0.block.2.fc1.weight] shape:[(4, 96, 1, 1)].\n",
      "    val:[-0.089 -0.141 -0.032  0.035 -0.144]\n",
      "[20] name:[features.2.0.block.2.fc1.bias] shape:[(4,)].\n",
      "    val:[ 0.483  1.883 -0.028 -0.159]\n",
      "[21] name:[features.2.0.block.2.fc2.weight] shape:[(96, 4, 1, 1)].\n",
      "    val:[-0.014  0.088 -0.119 -0.096  0.058]\n",
      "[22] name:[features.2.0.block.2.fc2.bias] shape:[(96,)].\n",
      "    val:[2.006 0.558 0.866 0.813 1.582]\n",
      "[23] name:[features.2.0.block.3.0.weight] shape:[(24, 96, 1, 1)].\n",
      "    val:[ 0.229 -0.191  0.279  0.    -0.228]\n",
      "[24] name:[features.2.0.block.3.1.weight] shape:[(24,)].\n",
      "    val:[6.577 7.187 5.443 8.364 7.023]\n",
      "[25] name:[features.2.0.block.3.1.bias] shape:[(24,)].\n",
      "    val:[ 0.004  0.001 -0.004 -0.002 -0.001]\n",
      "[26] name:[features.2.1.block.0.0.weight] shape:[(144, 24, 1, 1)].\n",
      "    val:[-0.221 -0.054  0.058 -0.242  0.105]\n",
      "[27] name:[features.2.1.block.0.1.weight] shape:[(144,)].\n",
      "    val:[2.051 2.898 2.412 2.673 2.324]\n",
      "[28] name:[features.2.1.block.0.1.bias] shape:[(144,)].\n",
      "    val:[ 2.402 -2.319 -0.257 -2.673  4.041]\n",
      "[29] name:[features.2.1.block.1.0.weight] shape:[(144, 1, 3, 3)].\n",
      "    val:[-0.186 -0.111 -0.171 -0.194  0.96 ]\n",
      "[30] name:[features.2.1.block.1.1.weight] shape:[(144,)].\n",
      "    val:[1.506 1.785 2.388 2.66  3.241]\n",
      "[31] name:[features.2.1.block.1.1.bias] shape:[(144,)].\n",
      "    val:[ 0.097 -0.046  0.548 -3.223 -2.483]\n",
      "[32] name:[features.2.1.block.2.fc1.weight] shape:[(6, 144, 1, 1)].\n",
      "    val:[ 0.03   0.037 -0.015 -0.125 -0.215]\n",
      "[33] name:[features.2.1.block.2.fc1.bias] shape:[(6,)].\n",
      "    val:[-0.414 -0.725  2.359  1.499  2.614]\n",
      "[34] name:[features.2.1.block.2.fc2.weight] shape:[(144, 6, 1, 1)].\n",
      "    val:[-0.02   0.03   0.015 -0.094 -0.059]\n",
      "[35] name:[features.2.1.block.2.fc2.bias] shape:[(144,)].\n",
      "    val:[2.154 0.77  0.298 2.044 2.278]\n",
      "[36] name:[features.2.1.block.3.0.weight] shape:[(24, 144, 1, 1)].\n",
      "    val:[ 0.041 -0.003 -0.022  0.276 -0.016]\n",
      "[37] name:[features.2.1.block.3.1.weight] shape:[(24,)].\n",
      "    val:[5.694 4.369 0.991 4.913 5.418]\n",
      "[38] name:[features.2.1.block.3.1.bias] shape:[(24,)].\n",
      "    val:[ 3.965  3.311 -0.027 -2.756 -1.848]\n",
      "[39] name:[features.3.0.block.0.0.weight] shape:[(144, 24, 1, 1)].\n",
      "    val:[-0.253 -0.21   1.038  0.038  0.016]\n",
      "[40] name:[features.3.0.block.0.1.weight] shape:[(144,)].\n",
      "    val:[2.001 0.975 3.601 2.792 0.408]\n",
      "[41] name:[features.3.0.block.0.1.bias] shape:[(144,)].\n",
      "    val:[ 0.936  0.311 -1.457  2.454  0.057]\n",
      "[42] name:[features.3.0.block.1.0.weight] shape:[(144, 1, 5, 5)].\n",
      "    val:[-0.04  -0.011  0.101  0.131  0.096]\n",
      "[43] name:[features.3.0.block.1.1.weight] shape:[(144,)].\n",
      "    val:[1.081 1.25  2.414 1.084 2.587]\n",
      "[44] name:[features.3.0.block.1.1.bias] shape:[(144,)].\n",
      "    val:[ 1.301  3.005 -0.558  2.297  0.011]\n",
      "[45] name:[features.3.0.block.2.fc1.weight] shape:[(6, 144, 1, 1)].\n",
      "    val:[-0.058 -0.073  0.046  0.1    0.026]\n",
      "[46] name:[features.3.0.block.2.fc1.bias] shape:[(6,)].\n",
      "    val:[1.57  0.717 0.305 0.217 0.91 ]\n",
      "[47] name:[features.3.0.block.2.fc2.weight] shape:[(144, 6, 1, 1)].\n",
      "    val:[ 0.167 -0.027  0.093  0.006 -0.02 ]\n",
      "[48] name:[features.3.0.block.2.fc2.bias] shape:[(144,)].\n",
      "    val:[2.046 2.    1.758 1.179 1.006]\n",
      "[49] name:[features.3.0.block.3.0.weight] shape:[(40, 144, 1, 1)].\n",
      "    val:[ 0.084  0.195 -0.532  0.301 -0.005]\n",
      "[50] name:[features.3.0.block.3.1.weight] shape:[(40,)].\n",
      "    val:[9.997 5.064 5.198 5.79  5.676]\n",
      "[51] name:[features.3.0.block.3.1.bias] shape:[(40,)].\n",
      "    val:[-0.003  0.     0.     0.    -0.   ]\n",
      "[52] name:[features.3.1.block.0.0.weight] shape:[(240, 40, 1, 1)].\n",
      "    val:[-0.405  0.067 -0.15  -0.017 -0.002]\n",
      "[53] name:[features.3.1.block.0.1.weight] shape:[(240,)].\n",
      "    val:[1.512 2.53  1.397 1.477 0.663]\n",
      "[54] name:[features.3.1.block.0.1.bias] shape:[(240,)].\n",
      "    val:[ 3.884 -0.114 -1.134  2.55   1.703]\n",
      "[55] name:[features.3.1.block.1.0.weight] shape:[(240, 1, 5, 5)].\n",
      "    val:[0.103 0.052 0.04  0.057 0.112]\n",
      "[56] name:[features.3.1.block.1.1.weight] shape:[(240,)].\n",
      "    val:[0.618 4.404 0.677 1.448 1.482]\n",
      "[57] name:[features.3.1.block.1.1.bias] shape:[(240,)].\n",
      "    val:[ 0.692 -3.226  1.326 -1.    -0.789]\n",
      "[58] name:[features.3.1.block.2.fc1.weight] shape:[(10, 240, 1, 1)].\n",
      "    val:[ 0.039 -0.063  0.013 -0.191 -0.207]\n",
      "[59] name:[features.3.1.block.2.fc1.bias] shape:[(10,)].\n",
      "    val:[ 1.048  1.018  2.487 -0.07   1.675]\n",
      "[60] name:[features.3.1.block.2.fc2.weight] shape:[(240, 10, 1, 1)].\n",
      "    val:[-0.14   0.025  0.07  -0.015  0.056]\n",
      "[61] name:[features.3.1.block.2.fc2.bias] shape:[(240,)].\n",
      "    val:[0.566 0.144 1.102 0.76  0.331]\n",
      "[62] name:[features.3.1.block.3.0.weight] shape:[(40, 240, 1, 1)].\n",
      "    val:[ 0.033 -0.05   0.01   0.01   0.161]\n",
      "[63] name:[features.3.1.block.3.1.weight] shape:[(40,)].\n",
      "    val:[1.243 1.949 3.382 2.72  1.932]\n",
      "[64] name:[features.3.1.block.3.1.bias] shape:[(40,)].\n",
      "    val:[ 1.929 -0.834 -2.565 -1.907 -1.842]\n",
      "[65] name:[features.4.0.block.0.0.weight] shape:[(240, 40, 1, 1)].\n",
      "    val:[ 0.31   0.025  0.136 -0.301 -0.17 ]\n",
      "[66] name:[features.4.0.block.0.1.weight] shape:[(240,)].\n",
      "    val:[0.83  0.783 0.586 0.899 1.118]\n",
      "[67] name:[features.4.0.block.0.1.bias] shape:[(240,)].\n",
      "    val:[-0.879 -0.987 -0.973 -0.938 -1.373]\n",
      "[68] name:[features.4.0.block.1.0.weight] shape:[(240, 1, 3, 3)].\n",
      "    val:[0.077 0.172 0.126 0.15  0.327]\n",
      "[69] name:[features.4.0.block.1.1.weight] shape:[(240,)].\n",
      "    val:[1.257 1.269 1.522 1.238 1.835]\n",
      "[70] name:[features.4.0.block.1.1.bias] shape:[(240,)].\n",
      "    val:[ 2.817  2.849  2.935  2.935 -0.071]\n",
      "[71] name:[features.4.0.block.2.fc1.weight] shape:[(10, 240, 1, 1)].\n",
      "    val:[-0.044 -0.077  0.122  0.011 -0.084]\n",
      "[72] name:[features.4.0.block.2.fc1.bias] shape:[(10,)].\n",
      "    val:[-0.269 -0.343 -0.228 -0.403  0.199]\n",
      "[73] name:[features.4.0.block.2.fc2.weight] shape:[(240, 10, 1, 1)].\n",
      "    val:[-0.275  0.09  -0.063 -0.112 -0.046]\n",
      "[74] name:[features.4.0.block.2.fc2.bias] shape:[(240,)].\n",
      "    val:[-0.421 -0.626 -1.352 -0.731  0.69 ]\n",
      "[75] name:[features.4.0.block.3.0.weight] shape:[(80, 240, 1, 1)].\n",
      "    val:[ 0.105 -0.228 -0.059 -0.153  0.083]\n",
      "[76] name:[features.4.0.block.3.1.weight] shape:[(80,)].\n",
      "    val:[4.933 4.635 5.644 6.02  5.464]\n",
      "[77] name:[features.4.0.block.3.1.bias] shape:[(80,)].\n",
      "    val:[ 3.920e-04 -1.730e-04 -3.079e-05  7.022e-04  1.041e-04]\n",
      "[78] name:[features.4.1.block.0.0.weight] shape:[(480, 80, 1, 1)].\n",
      "    val:[-0.11  -0.043  0.06  -0.062  0.036]\n",
      "[79] name:[features.4.1.block.0.1.weight] shape:[(480,)].\n",
      "    val:[0.766 0.715 1.927 1.384 0.649]\n",
      "[80] name:[features.4.1.block.0.1.bias] shape:[(480,)].\n",
      "    val:[-0.206  1.105 -0.135 -1.795  0.66 ]\n",
      "[81] name:[features.4.1.block.1.0.weight] shape:[(480, 1, 3, 3)].\n",
      "    val:[-0.008 -0.002  0.002  0.008  0.358]\n",
      "[82] name:[features.4.1.block.1.1.weight] shape:[(480,)].\n",
      "    val:[0.754 1.54  1.524 0.432 1.184]\n",
      "[83] name:[features.4.1.block.1.1.bias] shape:[(480,)].\n",
      "    val:[-3.799e-01 -1.224e+00 -4.503e-01  5.042e-04 -1.126e+00]\n",
      "[84] name:[features.4.1.block.2.fc1.weight] shape:[(20, 480, 1, 1)].\n",
      "    val:[-0.036 -0.025  0.024  0.064 -0.068]\n",
      "[85] name:[features.4.1.block.2.fc1.bias] shape:[(20,)].\n",
      "    val:[0.855 1.761 0.836 0.438 1.983]\n",
      "[86] name:[features.4.1.block.2.fc2.weight] shape:[(480, 20, 1, 1)].\n",
      "    val:[ 0.152  0.118 -0.188  0.004  0.07 ]\n",
      "[87] name:[features.4.1.block.2.fc2.bias] shape:[(480,)].\n",
      "    val:[-0.199  0.315  0.642  0.519  0.988]\n",
      "[88] name:[features.4.1.block.3.0.weight] shape:[(80, 480, 1, 1)].\n",
      "    val:[ 0.081 -0.064  0.147  0.126  0.072]\n",
      "[89] name:[features.4.1.block.3.1.weight] shape:[(80,)].\n",
      "    val:[2.133 2.02  1.955 1.734 1.394]\n",
      "[90] name:[features.4.1.block.3.1.bias] shape:[(80,)].\n",
      "    val:[ 0.804  0.447  0.232  0.978 -0.715]\n",
      "[91] name:[features.4.2.block.0.0.weight] shape:[(480, 80, 1, 1)].\n",
      "    val:[-0.067 -0.053 -0.053  0.061 -0.013]\n",
      "[92] name:[features.4.2.block.0.1.weight] shape:[(480,)].\n",
      "    val:[0.611 1.124 0.407 1.168 1.108]\n",
      "[93] name:[features.4.2.block.0.1.bias] shape:[(480,)].\n",
      "    val:[ 0.878 -1.38   0.588 -1.437 -0.685]\n",
      "[94] name:[features.4.2.block.1.0.weight] shape:[(480, 1, 3, 3)].\n",
      "    val:[ 0.048 -0.195  0.068  0.147 -0.161]\n",
      "[95] name:[features.4.2.block.1.1.weight] shape:[(480,)].\n",
      "    val:[1.324 0.651 1.379 2.089 1.596]\n",
      "[96] name:[features.4.2.block.1.1.bias] shape:[(480,)].\n",
      "    val:[-1.254 -1.104 -1.15  -0.074 -3.508]\n",
      "[97] name:[features.4.2.block.2.fc1.weight] shape:[(20, 480, 1, 1)].\n",
      "    val:[-0.074  0.055  0.027  0.028  0.036]\n",
      "[98] name:[features.4.2.block.2.fc1.bias] shape:[(20,)].\n",
      "    val:[2.043 1.171 0.488 1.238 0.024]\n",
      "[99] name:[features.4.2.block.2.fc2.weight] shape:[(480, 20, 1, 1)].\n",
      "    val:[-0.011 -0.071 -0.065  0.017  0.033]\n",
      "[100] name:[features.4.2.block.2.fc2.bias] shape:[(480,)].\n",
      "    val:[-0.041 -0.411 -0.24  -1.58   0.222]\n",
      "[101] name:[features.4.2.block.3.0.weight] shape:[(80, 480, 1, 1)].\n",
      "    val:[ 0.029 -0.13   0.043  0.046 -0.   ]\n",
      "[102] name:[features.4.2.block.3.1.weight] shape:[(80,)].\n",
      "    val:[2.215 1.848 1.524 1.255 1.366]\n",
      "[103] name:[features.4.2.block.3.1.bias] shape:[(80,)].\n",
      "    val:[ 0.523 -0.214  0.595  0.809 -0.266]\n",
      "[104] name:[features.5.0.block.0.0.weight] shape:[(480, 80, 1, 1)].\n",
      "    val:[-0.003 -0.095  0.025 -0.039  0.019]\n",
      "[105] name:[features.5.0.block.0.1.weight] shape:[(480,)].\n",
      "    val:[1.713 1.768 0.046 1.837 0.75 ]\n",
      "[106] name:[features.5.0.block.0.1.bias] shape:[(480,)].\n",
      "    val:[ 0.743  0.622 -0.035  2.299 -0.888]\n",
      "[107] name:[features.5.0.block.1.0.weight] shape:[(480, 1, 5, 5)].\n",
      "    val:[ 0.026 -0.024 -0.026 -0.015  0.015]\n",
      "[108] name:[features.5.0.block.1.1.weight] shape:[(480,)].\n",
      "    val:[1.001 0.636 1.515 0.907 0.747]\n",
      "[109] name:[features.5.0.block.1.1.bias] shape:[(480,)].\n",
      "    val:[ 0.124  0.507  1.162  0.198 -0.502]\n",
      "[110] name:[features.5.0.block.2.fc1.weight] shape:[(20, 480, 1, 1)].\n",
      "    val:[ 0.005  0.081  0.142 -0.118 -0.095]\n",
      "[111] name:[features.5.0.block.2.fc1.bias] shape:[(20,)].\n",
      "    val:[0.768 0.536 1.886 1.203 1.471]\n",
      "[112] name:[features.5.0.block.2.fc2.weight] shape:[(480, 20, 1, 1)].\n",
      "    val:[ 0.045  0.055  0.029 -0.057  0.02 ]\n",
      "[113] name:[features.5.0.block.2.fc2.bias] shape:[(480,)].\n",
      "    val:[ 1.785  2.344 -0.846  2.042  0.586]\n",
      "[114] name:[features.5.0.block.3.0.weight] shape:[(112, 480, 1, 1)].\n",
      "    val:[ 0.03   0.202 -0.256 -0.055  0.083]\n",
      "[115] name:[features.5.0.block.3.1.weight] shape:[(112,)].\n",
      "    val:[4.422 5.305 5.351 4.969 4.502]\n",
      "[116] name:[features.5.0.block.3.1.bias] shape:[(112,)].\n",
      "    val:[-2.423e-04 -2.037e-04  5.291e-04 -7.492e-04 -9.061e-05]\n",
      "[117] name:[features.5.1.block.0.0.weight] shape:[(672, 112, 1, 1)].\n",
      "    val:[ 0.03  -0.008  0.132 -0.032  0.108]\n",
      "[118] name:[features.5.1.block.0.1.weight] shape:[(672,)].\n",
      "    val:[0.686 1.264 0.243 1.137 1.217]\n",
      "[119] name:[features.5.1.block.0.1.bias] shape:[(672,)].\n",
      "    val:[-0.183 -0.534  0.204 -1.487 -1.025]\n",
      "[120] name:[features.5.1.block.1.0.weight] shape:[(672, 1, 5, 5)].\n",
      "    val:[-0.011  0.007  0.01   0.002 -0.016]\n",
      "[121] name:[features.5.1.block.1.1.weight] shape:[(672,)].\n",
      "    val:[1.609 1.521 1.655 0.476 1.473]\n",
      "[122] name:[features.5.1.block.1.1.bias] shape:[(672,)].\n",
      "    val:[-1.501  0.005 -0.952  0.387 -0.496]\n",
      "[123] name:[features.5.1.block.2.fc1.weight] shape:[(28, 672, 1, 1)].\n",
      "    val:[ 0.059 -0.074 -0.063 -0.028 -0.054]\n",
      "[124] name:[features.5.1.block.2.fc1.bias] shape:[(28,)].\n",
      "    val:[0.792 0.681 1.029 1.179 1.594]\n",
      "[125] name:[features.5.1.block.2.fc2.weight] shape:[(672, 28, 1, 1)].\n",
      "    val:[ 0.013 -0.075 -0.027  0.002 -0.079]\n",
      "[126] name:[features.5.1.block.2.fc2.bias] shape:[(672,)].\n",
      "    val:[ 0.154 -0.897 -0.019  0.336  0.279]\n",
      "[127] name:[features.5.1.block.3.0.weight] shape:[(112, 672, 1, 1)].\n",
      "    val:[ 0.005 -0.027 -0.064 -0.001  0.031]\n",
      "[128] name:[features.5.1.block.3.1.weight] shape:[(112,)].\n",
      "    val:[1.584 1.973 1.104 0.881 1.845]\n",
      "[129] name:[features.5.1.block.3.1.bias] shape:[(112,)].\n",
      "    val:[-0.454  0.146 -0.185  0.008 -0.698]\n",
      "[130] name:[features.5.2.block.0.0.weight] shape:[(672, 112, 1, 1)].\n",
      "    val:[ 0.04   0.186 -0.091 -0.049  0.153]\n",
      "[131] name:[features.5.2.block.0.1.weight] shape:[(672,)].\n",
      "    val:[1.093 0.874 1.251 1.383 0.216]\n",
      "[132] name:[features.5.2.block.0.1.bias] shape:[(672,)].\n",
      "    val:[-0.807 -1.174 -1.027 -1.644 -0.045]\n",
      "[133] name:[features.5.2.block.1.0.weight] shape:[(672, 1, 5, 5)].\n",
      "    val:[ 0.021  0.001 -0.161 -0.01   0.017]\n",
      "[134] name:[features.5.2.block.1.1.weight] shape:[(672,)].\n",
      "    val:[0.348 1.742 1.26  0.435 1.669]\n",
      "[135] name:[features.5.2.block.1.1.bias] shape:[(672,)].\n",
      "    val:[ 0.884 -2.445 -0.263  0.475 -1.418]\n",
      "[136] name:[features.5.2.block.2.fc1.weight] shape:[(28, 672, 1, 1)].\n",
      "    val:[ 0.067 -0.047  0.005 -0.055 -0.066]\n",
      "[137] name:[features.5.2.block.2.fc1.bias] shape:[(28,)].\n",
      "    val:[0.599 0.901 0.472 0.733 0.547]\n",
      "[138] name:[features.5.2.block.2.fc2.weight] shape:[(672, 28, 1, 1)].\n",
      "    val:[-0.121 -0.024  0.019  0.12   0.076]\n",
      "[139] name:[features.5.2.block.2.fc2.bias] shape:[(672,)].\n",
      "    val:[ 0.282 -0.363 -0.185  0.905 -0.577]\n",
      "[140] name:[features.5.2.block.3.0.weight] shape:[(112, 672, 1, 1)].\n",
      "    val:[-0.016  0.037 -0.107 -0.046 -0.063]\n",
      "[141] name:[features.5.2.block.3.1.weight] shape:[(112,)].\n",
      "    val:[1.368 1.861 0.923 0.879 1.693]\n",
      "[142] name:[features.5.2.block.3.1.bias] shape:[(112,)].\n",
      "    val:[-0.108  0.228 -0.146 -0.042 -0.43 ]\n",
      "[143] name:[features.6.0.block.0.0.weight] shape:[(672, 112, 1, 1)].\n",
      "    val:[ 0.003  0.214 -0.055  0.009 -0.007]\n",
      "[144] name:[features.6.0.block.0.1.weight] shape:[(672,)].\n",
      "    val:[0.753 0.392 2.405 0.922 0.895]\n",
      "[145] name:[features.6.0.block.0.1.bias] shape:[(672,)].\n",
      "    val:[-1.156 -0.012  0.788 -1.77  -1.637]\n",
      "[146] name:[features.6.0.block.1.0.weight] shape:[(672, 1, 5, 5)].\n",
      "    val:[ 0.024 -0.015 -0.046 -0.038  0.003]\n",
      "[147] name:[features.6.0.block.1.1.weight] shape:[(672,)].\n",
      "    val:[0.895 0.844 2.845 0.691 0.665]\n",
      "[148] name:[features.6.0.block.1.1.bias] shape:[(672,)].\n",
      "    val:[1.05  2.291 3.825 1.768 1.39 ]\n",
      "[149] name:[features.6.0.block.2.fc1.weight] shape:[(28, 672, 1, 1)].\n",
      "    val:[ 0.036 -0.02   0.016  0.006  0.015]\n",
      "[150] name:[features.6.0.block.2.fc1.bias] shape:[(28,)].\n",
      "    val:[0.643 1.603 0.423 2.268 0.798]\n",
      "[151] name:[features.6.0.block.2.fc2.weight] shape:[(672, 28, 1, 1)].\n",
      "    val:[ 0.038  0.023  0.019 -0.03   0.004]\n",
      "[152] name:[features.6.0.block.2.fc2.bias] shape:[(672,)].\n",
      "    val:[ 0.954  2.008 -0.692  1.644  1.468]\n",
      "[153] name:[features.6.0.block.3.0.weight] shape:[(192, 672, 1, 1)].\n",
      "    val:[-0.074  0.051  0.162 -0.053 -0.147]\n",
      "[154] name:[features.6.0.block.3.1.weight] shape:[(192,)].\n",
      "    val:[4.087 5.638 5.531 4.085 4.014]\n",
      "[155] name:[features.6.0.block.3.1.bias] shape:[(192,)].\n",
      "    val:[-5.031e-04 -9.444e-04 -2.019e-04  3.585e-05  7.164e-04]\n",
      "[156] name:[features.6.1.block.0.0.weight] shape:[(1152, 192, 1, 1)].\n",
      "    val:[-0.057  0.008  0.081 -0.025  0.008]\n",
      "[157] name:[features.6.1.block.0.1.weight] shape:[(1152,)].\n",
      "    val:[2.23  0.745 0.795 1.229 0.822]\n",
      "[158] name:[features.6.1.block.0.1.bias] shape:[(1152,)].\n",
      "    val:[-0.817 -0.925 -1.102 -2.093 -0.854]\n",
      "[159] name:[features.6.1.block.1.0.weight] shape:[(1152, 1, 5, 5)].\n",
      "    val:[-0.036 -0.024 -0.041 -0.025 -0.043]\n",
      "[160] name:[features.6.1.block.1.1.weight] shape:[(1152,)].\n",
      "    val:[1.913 1.755 1.94  1.811 0.886]\n",
      "[161] name:[features.6.1.block.1.1.bias] shape:[(1152,)].\n",
      "    val:[-0.09  -2.54  -2.588 -1.112 -0.533]\n",
      "[162] name:[features.6.1.block.2.fc1.weight] shape:[(48, 1152, 1, 1)].\n",
      "    val:[ 0.109 -0.044 -0.119 -0.037  0.078]\n",
      "[163] name:[features.6.1.block.2.fc1.bias] shape:[(48,)].\n",
      "    val:[ 0.548  0.278 -0.031  0.099  0.138]\n",
      "[164] name:[features.6.1.block.2.fc2.weight] shape:[(1152, 48, 1, 1)].\n",
      "    val:[ 0.135  0.049 -0.072 -0.059  0.036]\n",
      "[165] name:[features.6.1.block.2.fc2.bias] shape:[(1152,)].\n",
      "    val:[-1.009  0.123  0.591 -1.015 -0.286]\n",
      "[166] name:[features.6.1.block.3.0.weight] shape:[(192, 1152, 1, 1)].\n",
      "    val:[ 0.018  0.023  0.031  0.094 -0.015]\n",
      "[167] name:[features.6.1.block.3.1.weight] shape:[(192,)].\n",
      "    val:[1.256 0.994 1.09  1.305 1.996]\n",
      "[168] name:[features.6.1.block.3.1.bias] shape:[(192,)].\n",
      "    val:[-0.025 -0.337  0.164 -0.251 -0.541]\n",
      "[169] name:[features.6.2.block.0.0.weight] shape:[(1152, 192, 1, 1)].\n",
      "    val:[-0.034  0.012 -0.157  0.073 -0.061]\n",
      "[170] name:[features.6.2.block.0.1.weight] shape:[(1152,)].\n",
      "    val:[0.58  0.333 0.164 1.083 0.064]\n",
      "[171] name:[features.6.2.block.0.1.bias] shape:[(1152,)].\n",
      "    val:[-4.128e-01 -1.343e-02 -4.405e-04 -1.133e+00  3.828e-02]\n",
      "[172] name:[features.6.2.block.1.0.weight] shape:[(1152, 1, 5, 5)].\n",
      "    val:[0.014 0.007 0.018 0.007 0.02 ]\n",
      "[173] name:[features.6.2.block.1.1.weight] shape:[(1152,)].\n",
      "    val:[1.203 2.113 1.931 1.144 1.998]\n",
      "[174] name:[features.6.2.block.1.1.bias] shape:[(1152,)].\n",
      "    val:[-0.872 -0.948 -0.904 -1.026 -1.903]\n",
      "[175] name:[features.6.2.block.2.fc1.weight] shape:[(48, 1152, 1, 1)].\n",
      "    val:[ 0.037 -0.083  0.017 -0.028 -0.034]\n",
      "[176] name:[features.6.2.block.2.fc1.bias] shape:[(48,)].\n",
      "    val:[-0.69   1.734  0.441  0.184 -0.227]\n",
      "[177] name:[features.6.2.block.2.fc2.weight] shape:[(1152, 48, 1, 1)].\n",
      "    val:[-0.103  0.016 -0.045  0.023  0.051]\n",
      "[178] name:[features.6.2.block.2.fc2.bias] shape:[(1152,)].\n",
      "    val:[-1.251 -0.767 -0.183 -0.254 -0.109]\n",
      "[179] name:[features.6.2.block.3.0.weight] shape:[(192, 1152, 1, 1)].\n",
      "    val:[-0.077 -0.015  0.017  0.026  0.036]\n",
      "[180] name:[features.6.2.block.3.1.weight] shape:[(192,)].\n",
      "    val:[1.317 0.964 1.008 1.382 1.824]\n",
      "[181] name:[features.6.2.block.3.1.bias] shape:[(192,)].\n",
      "    val:[-0.207 -0.248  0.148 -0.354 -0.531]\n",
      "[182] name:[features.6.3.block.0.0.weight] shape:[(1152, 192, 1, 1)].\n",
      "    val:[-0.066 -0.03   0.019 -0.064 -0.001]\n",
      "[183] name:[features.6.3.block.0.1.weight] shape:[(1152,)].\n",
      "    val:[1.046 1.122 1.277 0.62  1.463]\n",
      "[184] name:[features.6.3.block.0.1.bias] shape:[(1152,)].\n",
      "    val:[-0.327 -1.61  -1.249 -0.618 -2.454]\n",
      "[185] name:[features.6.3.block.1.0.weight] shape:[(1152, 1, 5, 5)].\n",
      "    val:[ 0.019  0.006  0.006  0.032 -0.   ]\n",
      "[186] name:[features.6.3.block.1.1.weight] shape:[(1152,)].\n",
      "    val:[1.262 1.525 1.057 1.641 0.978]\n",
      "[187] name:[features.6.3.block.1.1.bias] shape:[(1152,)].\n",
      "    val:[-0.769 -3.265 -0.87  -0.698 -0.804]\n",
      "[188] name:[features.6.3.block.2.fc1.weight] shape:[(48, 1152, 1, 1)].\n",
      "    val:[-0.038  0.032 -0.042  0.023  0.062]\n",
      "[189] name:[features.6.3.block.2.fc1.bias] shape:[(48,)].\n",
      "    val:[ 1.86   0.055  0.174 -0.107  0.003]\n",
      "[190] name:[features.6.3.block.2.fc2.weight] shape:[(1152, 48, 1, 1)].\n",
      "    val:[-0.049 -0.045  0.018  0.303  0.01 ]\n",
      "[191] name:[features.6.3.block.2.fc2.bias] shape:[(1152,)].\n",
      "    val:[-1.026 -1.149 -0.307 -0.896 -0.389]\n",
      "[192] name:[features.6.3.block.3.0.weight] shape:[(192, 1152, 1, 1)].\n",
      "    val:[ 0.053 -0.036 -0.088  0.019  0.041]\n",
      "[193] name:[features.6.3.block.3.1.weight] shape:[(192,)].\n",
      "    val:[1.411 0.966 1.041 1.576 1.932]\n",
      "[194] name:[features.6.3.block.3.1.bias] shape:[(192,)].\n",
      "    val:[-0.071 -0.227  0.187 -0.22  -0.372]\n",
      "[195] name:[features.7.0.block.0.0.weight] shape:[(1152, 192, 1, 1)].\n",
      "    val:[-0.09  -0.006  0.011 -0.019 -0.112]\n",
      "[196] name:[features.7.0.block.0.1.weight] shape:[(1152,)].\n",
      "    val:[ 0.605  0.529  0.052  0.743 -0.613]\n",
      "[197] name:[features.7.0.block.0.1.bias] shape:[(1152,)].\n",
      "    val:[-0.877 -0.907  0.037 -1.058 -0.686]\n",
      "[198] name:[features.7.0.block.1.0.weight] shape:[(1152, 1, 3, 3)].\n",
      "    val:[0.031 0.105 0.034 0.103 0.145]\n",
      "[199] name:[features.7.0.block.1.1.weight] shape:[(1152,)].\n",
      "    val:[1.474 1.712 2.075 1.077 1.051]\n",
      "[200] name:[features.7.0.block.1.1.bias] shape:[(1152,)].\n",
      "    val:[-0.499 -2.237 -1.838 -0.102  0.275]\n",
      "[201] name:[features.7.0.block.2.fc1.weight] shape:[(48, 1152, 1, 1)].\n",
      "    val:[-0.06  -0.002  0.086  0.079 -0.036]\n",
      "[202] name:[features.7.0.block.2.fc1.bias] shape:[(48,)].\n",
      "    val:[-0.355 -1.191 -0.832 -0.781 -1.023]\n",
      "[203] name:[features.7.0.block.2.fc2.weight] shape:[(1152, 48, 1, 1)].\n",
      "    val:[-0.171 -0.16  -0.139 -0.069 -0.006]\n",
      "[204] name:[features.7.0.block.2.fc2.bias] shape:[(1152,)].\n",
      "    val:[0.567 0.723 1.378 0.887 0.798]\n",
      "[205] name:[features.7.0.block.3.0.weight] shape:[(320, 1152, 1, 1)].\n",
      "    val:[ 0.132 -0.023  0.006  0.158 -0.001]\n",
      "[206] name:[features.7.0.block.3.1.weight] shape:[(320,)].\n",
      "    val:[2.559 2.399 2.648 2.633 2.719]\n",
      "[207] name:[features.7.0.block.3.1.bias] shape:[(320,)].\n",
      "    val:[-0.     0.003  0.004  0.002 -0.008]\n",
      "[208] name:[features.8.0.weight] shape:[(1280, 320, 1, 1)].\n",
      "    val:[ 0.094 -0.018  0.013 -0.009  0.036]\n",
      "[209] name:[features.8.1.weight] shape:[(1280,)].\n",
      "    val:[2.376 2.799 2.812 2.799 2.739]\n",
      "[210] name:[features.8.1.bias] shape:[(1280,)].\n",
      "    val:[-1.791 -2.585 -2.339 -2.585 -2.577]\n",
      "[211] name:[classifier.1.weight] shape:[(18, 1280)].\n",
      "    val:[ 0.065  0.059 -0.013 -0.01   0.017]\n",
      "[212] name:[classifier.1.bias] shape:[(18,)].\n",
      "    val:[-0.005  0.025  0.019 -0.024  0.017]\n",
      "Total number of parameters:[4,030,606].\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "n_param = 0\n",
    "for p_idx, (param_name, param) in enumerate(model.named_parameters()):\n",
    "    if param.requires_grad:\n",
    "        param_numpy = param.detach().cpu().numpy()\n",
    "        n_param += len(param_numpy.reshape(-1))\n",
    "        print (\"[%d] name:[%s] shape:[%s].\"%(p_idx,param_name,param_numpy.shape))\n",
    "        print (\"    val:%s\"%(param_numpy.reshape(-1)[:5]))\n",
    "print (\"Total number of parameters:[%s].\"%(format(n_param,',d')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c067d0e-38c9-4ab8-baba-88cf8dcb8c6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[0/50] training loss 0.017, training accuracy 0.109\n",
      "Update checkpoint!!!\n",
      "[val] acc : 0.866, loss : 0.422, f1 score: 1.000\n",
      "best acc : 0.866, best loss : 0.422, best f1 : 1.000\n",
      "epoch[1/50] training loss 0.008, training accuracy 0.203\n",
      "Update checkpoint!!!\n",
      "[val] acc : 0.882, loss : 0.356, f1 score: 1.000\n",
      "best acc : 0.882, best loss : 0.356, best f1 : 1.000\n",
      "epoch[2/50] training loss 0.003, training accuracy 0.250\n",
      "Update checkpoint!!!\n",
      "[val] acc : 0.887, loss : 0.357, f1 score: 1.000\n",
      "best acc : 0.887, best loss : 0.356, best f1 : 1.000\n",
      "epoch[3/50] training loss 0.003, training accuracy 0.250\n",
      "Update checkpoint!!!\n",
      "[val] acc : 0.891, loss : 0.378, f1 score: 1.000\n",
      "best acc : 0.891, best loss : 0.356, best f1 : 1.000\n",
      "epoch[4/50] training loss 0.001, training accuracy 0.250\n",
      "Update checkpoint!!!\n",
      "[val] acc : 0.892, loss : 0.414, f1 score: 1.000\n",
      "best acc : 0.892, best loss : 0.356, best f1 : 1.000\n",
      "epoch[5/50] training loss 0.001, training accuracy 0.250\n",
      "[val] acc : 0.888, loss : 0.460, f1 score: 1.000\n",
      "best acc : 0.892, best loss : 0.356, best f1 : 1.000\n",
      "epoch[6/50] training loss 0.003, training accuracy 0.234\n",
      "[val] acc : 0.887, loss : 0.501, f1 score: 1.000\n",
      "best acc : 0.892, best loss : 0.356, best f1 : 1.000\n",
      "epoch[7/50] training loss 0.001, training accuracy 0.250\n",
      "[val] acc : 0.886, loss : 0.506, f1 score: 1.000\n",
      "best acc : 0.892, best loss : 0.356, best f1 : 1.000\n",
      "epoch[8/50] training loss 0.000, training accuracy 0.250\n",
      "[val] acc : 0.886, loss : 0.538, f1 score: 1.000\n",
      "best acc : 0.892, best loss : 0.356, best f1 : 1.000\n",
      "epoch[9/50] training loss 0.000, training accuracy 0.250\n",
      "Update checkpoint!!!\n",
      "[val] acc : 0.893, loss : 0.540, f1 score: 1.000\n",
      "best acc : 0.893, best loss : 0.356, best f1 : 1.000\n",
      "epoch[10/50] training loss 0.000, training accuracy 0.250\n",
      "[val] acc : 0.888, loss : 0.586, f1 score: 1.000\n",
      "best acc : 0.893, best loss : 0.356, best f1 : 1.000\n",
      "epoch[11/50] training loss 0.000, training accuracy 0.250\n",
      "[val] acc : 0.891, loss : 0.589, f1 score: 1.000\n",
      "best acc : 0.893, best loss : 0.356, best f1 : 1.000\n",
      "epoch[12/50] training loss 0.001, training accuracy 0.234\n",
      "[val] acc : 0.887, loss : 0.604, f1 score: 1.000\n",
      "best acc : 0.893, best loss : 0.356, best f1 : 1.000\n",
      "epoch[13/50] training loss 0.000, training accuracy 0.250\n",
      "[val] acc : 0.888, loss : 0.626, f1 score: 1.000\n",
      "best acc : 0.893, best loss : 0.356, best f1 : 1.000\n",
      "epoch[14/50] training loss 0.000, training accuracy 0.250\n",
      "[val] acc : 0.889, loss : 0.678, f1 score: 1.000\n",
      "best acc : 0.893, best loss : 0.356, best f1 : 1.000\n",
      "epoch[15/50] training loss 0.000, training accuracy 0.250\n",
      "[val] acc : 0.891, loss : 0.669, f1 score: 1.000\n",
      "best acc : 0.893, best loss : 0.356, best f1 : 1.000\n",
      "epoch[16/50] training loss 0.000, training accuracy 0.250\n",
      "[val] acc : 0.892, loss : 0.641, f1 score: 1.000\n",
      "best acc : 0.893, best loss : 0.356, best f1 : 1.000\n",
      "epoch[17/50] training loss 0.000, training accuracy 0.250\n",
      "Update checkpoint!!!\n",
      "[val] acc : 0.896, loss : 0.694, f1 score: 1.000\n",
      "best acc : 0.896, best loss : 0.356, best f1 : 1.000\n",
      "epoch[18/50] training loss 0.000, training accuracy 0.250\n",
      "[val] acc : 0.891, loss : 0.697, f1 score: 1.000\n",
      "best acc : 0.896, best loss : 0.356, best f1 : 1.000\n",
      "epoch[19/50] training loss 0.001, training accuracy 0.250\n",
      "[val] acc : 0.890, loss : 0.707, f1 score: 1.000\n",
      "best acc : 0.896, best loss : 0.356, best f1 : 1.000\n",
      "epoch[20/50] training loss 0.000, training accuracy 0.250\n",
      "[val] acc : 0.888, loss : 0.690, f1 score: 1.000\n",
      "best acc : 0.896, best loss : 0.356, best f1 : 1.000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-851876a6e09e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'differentiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[1;32m    232\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             adam(params_with_grad,\n\u001b[0m\u001b[1;32m    235\u001b[0m                  \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                  \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m     func(params,\n\u001b[0m\u001b[1;32m    301\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_val_acc = 0\n",
    "best_val_loss = np.inf\n",
    "patience = 10\n",
    "cur_count = 0\n",
    "\n",
    "f1 = F1Score(num_classes=class_num, average='macro').to(device)\n",
    "best_f1_score = 0\n",
    "\n",
    "for epoch in range(NUM_EPOCH):\n",
    "    model.train()\n",
    "    loss_value = 0\n",
    "    matches = 0\n",
    "    for train_batch in train_dataloader_mask:\n",
    "        inputs, labels = train_batch\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outs = model(inputs)\n",
    "        preds = torch.argmax(outs, dim=-1)\n",
    "        loss = criterion(outs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            torch.save(model, '/opt/ml/checkpoint/efficientNet/checkpoint_ep_%d.pt'% epoch)\n",
    "        \n",
    "        loss_value += loss.item()\n",
    "        matches += (preds == labels).sum().item()\n",
    "        \n",
    "        train_loss = loss_value / batch_size\n",
    "        train_acc = matches / batch_size\n",
    "        \n",
    "        loss_value = 0\n",
    "        matches = 0\n",
    "    print(f\"epoch[{epoch}/{NUM_EPOCH}] training loss {train_loss:.3f}, training accuracy {train_acc:.3f}\")\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        val_loss_items = []\n",
    "        val_acc_items = []\n",
    "        for val_batch in val_dataloader_mask:\n",
    "            inputs, labels = val_batch\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outs = model(inputs)\n",
    "            preds = torch.argmax(outs, dim=-1)\n",
    "            \n",
    "            loss_item = criterion(outs, labels).item()\n",
    "            acc_item = (labels==preds).sum().item()\n",
    "            val_loss_items.append(loss_item)\n",
    "            val_acc_items.append(acc_item)\n",
    "            \n",
    "        val_loss = np.sum(val_loss_items) / len(val_dataloader_mask)\n",
    "        val_acc = np.sum(val_acc_items) / len(mask_val_set)\n",
    "\n",
    "        f1_score = f1(outs, labels)\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "\n",
    "        if f1_score > best_f1_score:\n",
    "            best_f1_score = f1_score\n",
    "            \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            cur_count = 0\n",
    "            torch.save(model, '/opt/ml/checkpoint/efficientNet/checkpoint_best.pt')\n",
    "            print(\"Update checkpoint!!!\")\n",
    "        else:\n",
    "            cur_count += 1\n",
    "            if cur_count >= patience:\n",
    "                print(\"Early Stopping!\")\n",
    "                break\n",
    "            \n",
    "            \n",
    "        print(f\"[val] acc : {val_acc:.3f}, loss : {val_loss:.3f}, f1 score: {f1_score:.3f}\")\n",
    "        print(f\"best acc : {best_val_acc:.3f}, best loss : {best_val_loss:.3f}, best f1 : {best_f1_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "94e6d274-764e-4dca-9297-23241fb569b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best f1 score:1.0\n"
     ]
    }
   ],
   "source": [
    "print(f'Best f1 score:{best_f1_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "afda23d0-6ad9-408b-99c9-705ae5fd8347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageID</th>\n",
       "      <th>ans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cbc5c6e168e63498590db46022617123f1fe1268.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0e72482bf56b3581c081f7da2a6180b8792c7089.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b549040c49190cedc41327748aeb197c1670f14d.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4f9cb2a045c6d5b9e50ad3459ea7b791eb6e18bc.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>248428d9a4a5b6229a7081c32851b90cb8d38d0c.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ImageID  ans\n",
       "0  cbc5c6e168e63498590db46022617123f1fe1268.jpg    0\n",
       "1  0e72482bf56b3581c081f7da2a6180b8792c7089.jpg    0\n",
       "2  b549040c49190cedc41327748aeb197c1670f14d.jpg    0\n",
       "3  4f9cb2a045c6d5b9e50ad3459ea7b791eb6e18bc.jpg    0\n",
       "4  248428d9a4a5b6229a7081c32851b90cb8d38d0c.jpg    0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "test_dir_path = '/opt/ml/input/data/eval/'\n",
    "test_image_path = '/opt/ml/input/data/eval/images/'\n",
    "\n",
    "model = torch.load('/opt/ml/checkpoint/efficientNet/checkpoint_best.pt')\n",
    "submission = pd.read_csv(test_dir_path+'info.csv')\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "566c2df1-a083-4e27-a655-f2c73d15f762",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = [os.path.join(test_image_path, img_id) for img_id in submission.ImageID]\n",
    "test_image = pd.Series(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a9c14322-45a8-40a5-aded-f335204484b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test_Dataset(Dataset):\n",
    "    def __init__(self, midcrop=True, transform=None):\n",
    "        self.midcrop = midcrop\n",
    "        self.data = test_image\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(test_image)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.cvtColor(cv2.imread(self.data[idx]), cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.midcrop:\n",
    "            img = img[64:448]\n",
    "            \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "138db932-cc09-4f85-89d8-e7485659f7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test inference is done!\n"
     ]
    }
   ],
   "source": [
    "dataset = Test_Dataset(transform = transforms.Compose([\n",
    "                            transforms.ToTensor()\n",
    "                        ]))\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "# 모델을 정의합니다. (학습한 모델이 있다면 torch.load로 모델을 불러주세요!)\n",
    "device = torch.device('cuda')\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "all_predictions = []\n",
    "for images in loader:\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        pred = model(images)\n",
    "        pred = pred.argmax(dim=-1)\n",
    "        all_predictions.extend(pred.cpu().numpy())\n",
    "submission['ans'] = all_predictions\n",
    "\n",
    "# 제출할 파일을 저장합니다.\n",
    "submission.to_csv(os.path.join(test_dir_path, 'submission.csv'), index=False)\n",
    "print('test inference is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b7d263",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
